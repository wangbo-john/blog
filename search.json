[{"title":"并行性实验三：异构架构，VPU简介","url":"/blog/tech/heterogeneous-experience1-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n\nMovidius的Myriad视觉处理单元 (VPU) 是从头到脚按异构架构(heterogeneous soc architectures)设计的一款视频、AI处理加速器——就连目标任务都是异构的。\n\n这块单元上，我厂终于不再坚持使用x86核心，沿用了原有的sparc内核。\n这么不起眼的一步来之不易。前几年在NTG、MCG做平板和手机的时候，全力推动公司另行开发一条以功耗为首要目标的芯片产品线，结果被告知已经有人在做了，然后满心欢喜地发现是x86的Atom……好歹Atom现在要上火星了，不再说它。\n\n今天已经写了两篇，还不错。转钟了，睡觉去，后续具体内容TBD……\n","tags":["parallelism"],"categories":["tech"]},{"title":"并行性实验二：数据级并行性（DLP），NNP-I/NNP-T简介","url":"/blog/tech/DLP-experience1-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n\nSpring Hill 是基于传统CPU架构，关于提升数据级并行性（DLP）线程级并行性(TLP)的一种尝试。\nFB已经部署SPH。\n\n# Nervana的神经网络处理器和Spring Hill\n\nNervana 是一家总部位于加州的人工智能软件初创公司，提供全栈SaaS平台，帮企业开发定制的深度学习软件。 2016年8月9日，它被英特尔以约4.08亿美元的价格收购。\n神经网络处理器NNP就是这次收购的成果，当年号称运行速度10倍于当时的Nvidia Maxwell 架构GPUs。刚刚查了一下，Maxwell 架构是nVidia 2014-2015年的主流产品。\n\n# NNP-I推理加速器\n\n取一颗PC级8核Ice Lake处理器，去掉其中6核，换成6x2=12路NNP-I，就成了一种新的神经网络加速器架构，另取名Spring Hill。\n\n因为新架构过于简单，两种组件都是成熟产品，流片前流程相对轻松简单。重点关注LLC和ICE（推理引擎）之间的ACF模块和总线连接，无悬念直接流片成功。\n\nSpring Hill是英特尔用于神经处理器的第一代SoC微架构，目标是加快数据中心的**推理**速度。该设计针对数据中心推理负载，在10至50 W的功率范围内具有接近5 TOPS / w的性能/功效（实际为4.8），以维持轻巧的PCIe加速卡外形尺寸，例如M.2。选择形状因数和功率范围是因为它易于集成到现有基础架构中，而无需额外的冷却/功率容量。\n\n![sph_overview](/img/2020/ILPDLP/spring_hill_overview.png)\n图1 Spring Hill框图\n\n\n\n## 推理计算引擎（ICE）\n\n推理计算引擎（ICE）是推理负载的处理单元。 每个ICE包括四个主要组件——深度学习计算网格、可编程向量处理器、高带宽数据便笺存储器和大型本地SRAM。 向量处理器是VP6 DSP，旨在为ICE提供计算网格所不能提供的其他可编程性支持。向量处理器和计算网格使用纵贯整个引擎的同步总线进行通信和同步。 此外，两个处理元件还通过256 KiB的紧密耦合内存（TCM）紧密连接。\n\n![ice](/img/2020/ILPDLP/sph_ice.png)\n图2 推理引擎架构\n\n## 深度学习计算网格\n\n深度学习计算网格是一个大型4D结构，可提供4种并行方式。网格本身被组织为能够执行4K-MAC / 周期（int8）的32x32x4 4D网格 (MAC: multiply–accumulate，乘加)。它本身支持半精度浮点（FP16）以及8位，4位，2位甚至1位精度运算。网格的设计旨在通过将输入数据一次性广播至整个网格，来最大程度地减少数据移动。同样，在网格内，根据需要左右移动数据，可最大限度地提高数据重用性。这些计算网格可在编译时转换部分网格，来得到更好的硬件布局。\n\n计算网格将后处理单元与硬件强化的支持集成在一起，以支持各种非线性操作和池化。计算网格由可编程控制单元管理，该可编程控制单元可以跨网格以各种方式映射模型。网络映射的确切方式是在编译时静态预先确定的。另外，控制单元可以执行各种其他存储器和处理操作。\n\n![grid](/img/2020/ILPDLP/sph_dl_compute_grid.png)\n图3 DL计算网格\n\n\n\n## 可编程向量处理器\n为了获得更大的灵活性，每个ICE都配备了定制的Cadence Tensilica Vision P6 DSP。这是一个配置有两个512位矢量加载端口的5插槽VLIW 512位矢量处理器。它支持FP16以及8-32b整数运算。添加此DSP的目的是为了对计算网格以外的操作提供可编程支持。\n\n\n\n# NNP-T训练加速器\n\nSpring Crest（SCR）是Lake Crest的后继产品，架构上变化不大。Lake Crest是Nervana的首款商用神经处理器，已量产。该芯片本身是为数据中心DL训练而设计的。为此，它被设计为PCIe Gen 4 x16加速器卡和OCP加速器模块（OAM），作为150-250W典型工作负荷功率范围内的风冷设备。\n\n![diagram](/img/2020/ILPDLP/spring_crest_block_diagram.png)\n图4 Spring Crest框图\n\nSpring Crest是数据中心训练加速器，针对最快训练时间和最高功效进行了优化。重点放在对片上数据和批量负载的重用上。\n\n该芯片具有24个高性能张量处理器集群（TPC），每个集群都包含两个MAC处理单元（MPU）以及大量的高带宽内存池。每个MPU对集成一个32x32阵列，每个周期总共98,304个FLOP，总共可进行119 TOPS的计算。MPU由60 MiB的分布式SRAM供电。Spring Crest使用带32位（SP FP）累加的bfloat16。使用2D网格NoC链接整个芯片时，带宽在任何地方都比延迟更受青睐。\n\nSpring Crest采用台积电（TSMC）16纳米工艺制造，并利用其CoWoS 2.5D封装技术将四层HBM2（8Hi）集成在插入器上，总容量为32 GiB，工作速度为2400 MT / s。\n\n四个芯片间链接（ICL）包括x16（4×4）SerDes，总共64个SerDes。 ICL端口以112 Gbps的速度运行，总双向带宽为3.58 Tbps。由于采用了OAM标准，因此具有多个节点的系统扩展在很大程度上是无胶合的。一个完整的系统，最多包含1024个Spring Crest处理器，具有针对数据和模型并行性设计的一致编程模型。\n\n## 张量处理集群（TPC）\nSpring Crest的主要组件是Tensor Processing Cluster（TPC）。芯片上有24个相同的TPC实例。 TPC包含四个主要子系统：片上路由器（OCR），控件，MAC处理单元（MPU）和内存子系统。\n\n片上路由器有助于TPC之间以及共享外围设备（如PCIe和ICL接口）之间的数据通信。\n\n## 控制\n控制路径负责指令的解码，操作的调度和退出指令。控制还协调TPC中的计算块。 Spring Crest ISA是基于张量的有限指令集ISA。换句话说，所有操作数都被视为张量。 ISA附带许多本机张量操作（包括更专门的操作，例如转置和张量切片）。控制包括一个微控制器，该微控制器允许使用自定义微控制器指令扩展ISA。\n\n## MAC处理单元（MPU）\n每个TPC内都有两个计算块。该处理单元包括一个大型矩阵乘法数组以及矢量运算和专门的深度学习功能。矩阵乘法核心是一个32x32阵列，使用bfloat16进行乘法，使用FP32进行累加。阵列内的部分乘积缓冲区会累积部分乘积，以减少内存访问和功耗。英特尔之所以选择32x32，是因为它可以实现良好的数据重用，同时又要使其足够小，以免由于量化效应而损失很多性能。\n\n复合矢量流水线位于矩阵核心之外，该流水线可以对一组输入和中间值执行多项操作，从而减少了内存带宽和功耗。整个复合矢量流水线均支持FP32和BF16，还允许根据网络精度要求优化非GEMM操作。此外，矢量流水线还包括针对诸如激活函数、随机数生成、约简和累加之类的事物的专门优化。还支持可编程FP32查找表。\n\n## 内存子系统\n\n内存子系统负责通过计算块以及路由网格来获取和接收数据。每个TPC都包含2.5 MiB的本地暂存器内存。芯片上总共24个TPC，有60 MiB便笺存储器。该存储器具有高度划分内存的能力和多端口性，以便同时进行读写访问。作为内存端口的一部分，支持就地张量转置。换句话说，张量转置可以直接通过简单地读取和写入内存来完成，而无需任何额外的开销。计算模块和便笺存储区之间总共有1.4 Tbps的带宽。\n\n内存由软件明确管理，以优化数据局部性和数据驻留性——这适用于片上内存和片外HBM内存。为了不干扰软件优化，已将内存的硬件管理保持在最低限度。消息传递、内存分配和内存管理都在软件控制之下。该软件还可以在TPC以及HBM和内存bank之间直接传输内存内容。\n\n除了片上存储器外，Spring Crest还包括四层8-hi HBM2存储器。内存以2.4 GT / s的速度运行，总带宽为1.23 TB / s，容量为32 GiB。\n\n## 卷积引擎\n作为内存子系统的一部分，有数据转换卷积引擎。该引擎用于重新格式化卷积数据，并执行其他一些更常规的操作，例如张量整形。\n\n## 片上网络（NoC）\n\nSpring Crest集成了二维网格体系结构。 该芯片有四个吊舱，每象限一个。吊舱可用于本地化数据移动和重用。 每个吊舱包括六个TPC，并直接链接到最近的物理HBM。 共有三个全速双向网格——用于HBM，外部芯片间互连和相邻的吊舱。针对不同类型业务，设计不同的总线以减少相互间干扰。 每个方向上总共有1.3 TB / s的带宽，网络上总共有2.6 TB / s的横截面带宽。\n\n![NoC](/img/2020/ILPDLP/spring_crest_mesh.png)\n图5 NoC\n\n","tags":["parallelism"],"categories":["tech"]},{"title":"并行性实验一：指令级并行性（ILP），QVNNI指令集简介","url":"/blog/tech/ILP-experience1-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n\nQVNNI指令集 是基于传统CPU架构，关于提升指令级并行性（ILP）的一种尝试。\n亚马逊的AWS已经公开部署这套指令集。\n\n# QVNNI是什么？\n\n这是一个新的指令集，考虑到资源占用，复用了AVX-512的部分资源，于是变成了AVX-512的扩展。\n从名字就可以大致猜出它是什么，比如原名 512-bit wide Fused Multiply Add (FMA) core instructions （512比特宽度的乘加熔合核心指令），还有有相对正常点的曾用名，Vector Neural Network Instructions Word variable precision（可变精度向量神经网络指令）。如果客户反响好，它还有扩展到1024的打算，以支持更高精度。\n有了QVNNI指令集，只需要发射一条微码进FIT和OOO，执行单元就可以进行一系列的定点或浮点运算，完成一次矩阵乘法。它含有好几种不同指令，用来支持不同的数据格式，所以称为指令集。\n\n# 支持的数据类型\n\nQVNNI指令集有一个单独设计的执行单元，全流水，含4个浮点数学运算单元。\n它只需要一条微码，就可以计算出矩阵乘加运算 A * B + c 的结果。\n这是一个QVNNI微码的例子：VQVNNI dest, zmm0, m128，其中dest初始时存放上式中的c，全部计算结束后保存最终累加结果。\n\nQVNNI支持最常见的16位数字格式和8位数字格式，分别是16位IEEE浮点（fp16），bfloat16（bf16），16位整数（int16），8位整数（int8）和 8位微软浮点（ms-fp8）。 图1显示了其中某些格式之间的差异。\n\n![Data_Format](/img/2020/ILPDLP/numerical-formats-754765.png)\n图1 各种数字格式表示。s表示符号位。可以注意到， FP32和BF16拥有相同的动态范围，而FP32提供了更高的精度，因为它的尾数较长。\n\n# 支持的神经网络\n\n这种最基本的加速指令单元没有也不需要针对哪种深度神经网络结构做优化，所以除了少数比较极端的情况，可以支持几乎任何网络的加速。\n\n# 相对性能改善\n\n下面是在VNNI（QVNNI的简化版，仅支持int8和bf16,不支持单精度浮点）测得的int8相对fp32的性能改善。如果使用QVNNI，可让单精度浮点矩阵计算也得到同等程度的加速。\n\n基于以下三点原因：1）现代模型不再使用LRN（Local Response Normalization），可将部分较旧模型修改为使用批量规一化（Batch Normalization）。 2）softmax函数和BN需要全精度，因为它不能以8位精度保持原有的准确性。另外，3）不要在BN推理层后再进行卷积，因为它可以通过缩放权重值并修改“偏差”被其前一层吸收。英特尔MKL-DNN仅使用fp32，而没有以8位精度实现LRN，softmax或BN层。\n\n突然写了上面一大段有点莫名奇妙吧。自我翻译一下，这句话的意思是：下面的int8都是“天然无优化”结果，而MKL-DNN针对fp32有一定优化，所以如果双方待遇相同，int8能得到更好的优化结果。\n\n使用VNNI，简单测得的深度学习性能提升：\n\n| **Model**     | **Framework** | **Tuning Strategy** | **INT8 Tuning Accuracy** | **FP32 Accuracy Baseline** | **INT8/FP32 Acc Ratio**   **[(INT8-FP32)/FP32]** | **INT8/FP32 Perf Ratio** |\n| ----------------- | ------------- | ------------------- | ------------------------ | -------------------------- | ---------------- | ------------------------ |\n| ResNet50 V1   | TensorFlow    | mse                 | 73.28%                   | 73.54%                     | -0.35% | 2.99x |\n| ResNet50 V1.5 | TensorFlow    | bayesian            | 75.70%                   | 76.26%                     | -0.73% | 1.95x |\n| ResNet101     | TensorFlow    | basic               | 76.68%                   | 75.58%                     | 1.46% | 3.03x |\n| Inception V1  | TensorFlow    | basic               | 69.54%                   | 69.48%                     | 0.09% | 2.18x |\n| Inception V2  | TensorFlow    | basic               | 74.32%                   | 74.38%                     | -0.08% | 1.69x |\n\n| **Model**        | **Framework** | **Tuning Strategy** | **INT8 Tuning Accuracy** | **FP32 Accuracy Baseline** | **INT8/FP32 Acc Ratio**   **[(INT8-FP32)/FP32]** | **INT8/FP32 Perf Ratio** |\n| ---------------------- | ------------- | ------------------- | ------------------------ | -------------------------- | ---------------- | ------------------------ |\n| DLRM             | PyTorch       | basic               | 80.21%                   | 80.27%                     | -0.08% | 1.87x |\n| BERT-Large MRPC  | PyTorch       | basic               | 87.90%                   | 88.30%                     | -0.45% | 2.38x |\n| BERT-Large SQUAD | PyTorch       | basic               | 92.15%                   | 93.05%                     | -0.96% | 1.42x |\n| BERT-Large CoLA  | PyTorch       | basic               | 62.10%                   | 62.60%                     | -0.80% | 1.76x |\n| BERT-Base STS-B  | PyTorch       | basic               | 88.50%                   | 89.30%                     | -0.90% | 3.05x |\n\n| **Model**     | **Framework** | **Tuning Strategy** | **INT8 Tuning   Accuracy** | **FP32 Accuracy   Baseline** | **INT8/FP32 Acc   Ratio**   **[(INT8-FP32)/FP32]** | **INT8/FP32 Perf   Ratio** |\n| ------------------- | ------------- | ------------------- | -------------------------- | ---------------------------- | ------------------ | -------------------------- |\n| ResNet50 V1   | MXNet         | mse                 | 76.40%                     | 76.80%                       | -0.52% | 3.73x |\n| MobileNet V1  | MXNet         | mse                 | 71.60%                     | 72.10%                       | -0.69% | 3.02x |\n| MobileNet V2  | MXNet         | mse                 | 71.00%                     | 71.10%                       | -0.14% | 3.88x |\n| SSD-ResNet50  | MXNet         | basic               | 29.50%                     | 29.70%                       | -0.67% | 1.86x |\n| SqueezeNet V1 | MXNet         | mse                 | 57.30%                     | 57.20%                       | 0.18% | 2.88x |\n\n\n\n\n\n\n\n","tags":["parallelism"],"categories":["tech"]},{"title":"今月曾经照古人——史前天文与数学","url":"/blog/human/undefined-undefined.html","content":"#### 　　智人在各种人类和猛兽的丛林中战战兢兢存活下来，迫切希望能了解这个世界。高高在上性格各异的星辰无疑具有极其重大的启示作用。这些星辰很可能指示着人类的命运，那就观察观察，研究研究？\n\n#### 　　对于明确知道自己处在大陆东方的人类，他们比较幸运。虽然最亮的星星们好像都是全球共享，从一方升起、穿越天穹后在另一方落下，但是其中有一颗，却只在东方升起、落下。这颗眷顾东方的星辰逐渐培养了东方人祖先的一种信心和气魄：通过努力，可以掌控自己的命运。\n\n<!--more-->\n&nbsp;\n&nbsp;\n　　这是2020年4月19日凌晨4点，上海夜空中的景色，主角是太阳系最亮的几颗行星（还有一颗卫星——月球）：\n![古人也见过的木水火土星与月，再等一两小时金星与太阳同出](/img/2020/mu_huo_shui_moon_in_a_line.jpg \"曾照古人的星与月\")\n　　天空中最亮的几颗星排成整齐的一行，显得很特殊，和其它星星都不一样。\n　　远古时期的人类祖先，应该会比我们现代人更经常地观察天空，以获得上天的启示。他们肯定也经常看到图片中的景象。\n\n　　图片中的时间再过46分钟，尚未露面的大佬——太阳，发出的光芒，开始将天边染成橙黄，这时水星会悄悄露出地平线，肉眼可见。最有意思的是，新加入的这位水星，一眼就能看出和第一张图片中几颗星星是一伙的，因为新露面的水星和它们站在同一条直线上。\n![五星连珠](/img/2020/mu_huo_shui_moon_water_in_a_line.jpg \"五星连珠月亮算吗？\")\n\n　　这是地球人在天空中所能看到的最明亮的七颗星体，以及它们的亮度：\n\n| 天体 | 星等  |      | 天体 | 星等 |\n| :--: | :---: | :--: | :--: | :--: |\n| 太阳 | -26.7 |      | 木星 | -2.7 |\n| 满月 | -12.6 |      | 水星 | -1.9 |\n| 金星 | -4.4  |      | 土星 | -0.3 |\n|  |   |      | 火星 | -2.0 |\n\n　　星等就是亮度的数字化表示，星等值越小，那颗星就越亮（瞅瞅太阳的星等就很容易明白，哪种数字更亮）。\n\n　　古人很容易就能发现，最明亮的这些星星（包括太阳），一年中绝大多数时间都处在一条直线上。只有相互间几乎重合时才能看出它们之间并不是严格的直线，但是和巨大的天空背景相比，这种偏离直线的幅度很小。其实有那么一点点偏离，在原始人看来也许更说明星星们是有自主性的高级神仙，而不是单调死守规矩的机器人。有时候上表内一部分成员会隐没在地平线以下，可是它们从哪里升起、又从哪里沉入地平线，都是有规律可循的。\n\n　　为什么所有行星，包括太阳，会排成一条直线，而不像大雁那样一会儿一字一会儿人字？\n![黄道面](/img/2020/astronomy_and_math/黄道面.jpg \"黄道面\")\n![黄道面](/img/2020/astronomy_and_math/黄道面.gif \"黄道面\")\n　　因为太阳系所有行星都在一个称之为“黄道面”的平面内绕太阳运动。你假想一下太阳和所有行星，包括地球，都在同一张白纸上，从地球上看其它星球，它们是不是就一直在一条直线上？\n\n\n### 预测星星出现或隐没点\n　　既然已经知道这几颗星会排成一行，那么它们出现或隐没的那个点，就是天空中已有的亮仔成员连成的直线，和地平线之间的交点。\n　　于是形成最早的几何概念——两条直线，及其交点。\n\n### 发现星星活动有规律性\n　　通过坚持观测、记录，原始人会发现这几颗代表神仙的最亮的星星们的活动既有规律，又有各自的特点。\n　　它们每过一个固定的周期就会重复自己的行为。\n\n### 西方7天的来历\n　　上面表格里的7颗星，除了在全天域范围内亮度最高，它们还是太阳系内行星（含一颗特殊恒星），它们自行组队的行为明显区别于其它恒星。所以西方人把7作为一个重要的数字传承下来。后来圣经里就出现上帝花了6天时间创造世界，歇一天的故事，加起来正好是7天。\n\n\n\n\n　　下面这张表，是在地球上能观测到的行星运动周期，数万年前的古人和我们当代人的数据变动不大：\n\n|  最亮的星辰   | 公转周期（日）  | 换算成月 | 换算成年 |\n|  :---:  | :---:  | :---: | :---: |\n|  太阳   | 365有余，366不足 | 12 |  1  |\n|  月亮   | 30 | 1 |  1/12  |\n|  金星   | 224.7  | ~7.5 | 每两周期1¼年  |\n|  水星   | 87.9691  | ~3 | ¼  |\n|  木星   | 4332.589  | ~144 | 12  |\n|  土星   | 10832.327  | ~360 | 30  |\n|  火星   | 686.971  | ~22.6 | 1.88 |\n\n　　这些系内行星的公转周期很容易取整，火星是个例外，它总是带着很长而且不规律的小数部分。所以东西方最远古时代的原始人都没办法把它纳入某种神秘学说里，没有把它纳入常规观测范围内。\n\n### 地球人根据这张表得到12进制\n　　如果不算土星，前面日、月、金、水、木五颗星公转周期的最小公倍数是12。也就是说，每隔12年，站在地面观察的我们，就能看到 日、月、金、水、木 五颗星完全重复之前的轨迹，包括它们相互之间的站位，都非常完美地重复。\n　　观测天文活动，帮助最初的人类学到最小公倍数这样的数学概念。也许还不成系统，但数学慢慢总会发展起来。\n　　地面上，12个月盈月亏就是一年；天空中，每过12年，最亮的几颗星星们之间的关系就会重复一遍。\n　　最初的12进制在这样的重复熏陶之下，慢慢开始成型。\n　　西方人的祖先得到12进制后，就停下来了。\n　　因为他们发现超过12之后，事情会发生变化。\n　　因此，13是个特别不吉利的数字。\n　　比如，不信邪的耶稣收了13个徒弟，老13比前面12个徒弟都有名，他叫犹大。\n\n\n\n### 同样一群系内行星，我们不但得到12进制，还有一个中国特有的进制单位——60年一甲子\n\n　　12进制和西方一样，没啥好讲的。中国有十二生肖，我嘚瑟了吗？\n\n　　得到12进制后，中国人的祖先走得更远。\n　　西方放弃火星、土星，按道理那时人类文明还没有出现分支，中国大地上的人类祖先也应该放弃才是，因为观测这两颗行星的难度对于全体地球人都是一样的。但不同的是，我们祖先非常重视土星，一定要把它包含进自己的常规观测范围。\n　　为什么？\n　　除去很特别的日、月两位爸妈级别影响力的强力星球，夜空中满天星斗，其中最亮的、应当是神仙首领的4颗神秘星星，它们并不是满天空乱窜的，恰恰相反，它们的升降非常有规律。\n　　**金星**通常要等到后半夜才在东方、略偏东北的方向上升起，绕天行走到西方准备落下时，恰好是凌晨。所以勤劳早起的古人认为太白金星是居住在西方的启明星；\n　　**木星**下午时就从东方升起，等到傍晚天色暗下来看到它时，它已经挂在天空中很高的地方，然后慢慢滑经南方天空走到西方落下。落下时通常转钟不久（方言），也就是前后两天刚刚交替的子时（不到0:30就已完全落下）；再加上它的公转周期正好是12年，可以很方便地产生地支纪年法，于是古人称其为岁星。后来有传说它是位于东方的木之精华，是青帝之子，于是有了木星这个名字。至于木之精华这个传说的来源，是不是因为有超级远视眼（千里眼++）真的看到了木星的木纹，我就不知道了。\n　　**水星**是这几颗星里面最难观测的。它名叫水星，却偏偏常年都紧跟太阳，几乎总是出现在离太阳不远的方向上，像是太阳公公的随行秘书，因此也是昼出夜伏，停在我们头顶时就是正午时分，肉眼看不到。看到它的通常都以欣赏日出日落美景的人居多。不过这样一来，它的方位就很容易确定，相对于北半球中国土地上的人，它常年都处于偏南方的位置；\n　　前面三颗星都是满天跑，属于全人类的，尤其那颗住在西方的太白金星。\n　　可是还有这样一颗星——位列四大之一，却坚守东方，常年只在东方、略偏东南方向上升降，非常特别。它是太阳系第二大行星——**土星**。\n　　这就是为什么西方人不舍得花大力气，东方人却觉得需要认真观测土星的原因。土星对于东方的偏爱，不仅仅让我们祖先觉得有必要了解一下它，更在无意中从遥远的太空给这种挑战极限的科研行为以精神上的支持，一直培育着中国人祖先相对其它方向人类族群的优越感。\n　　很明显，中国人的祖先们认为天上住着神仙，这些明亮的星辰可能是神仙本仙、也可能是神仙的住处。星辰运动神秘而有规律，重复观察它们就能获得神仙们的一些启示。而对于其中常驻东方的土星，获得它的启示尤其重要。\n　　最早的负责天文观测的家族很可能就是黄帝家族，因为观测土星的职责或成就，而自称拥有土德。\n\n*【题外话】其实火星的升降规律和木星很接近，但它“无规律”的公转周期让人头疼。除了周期问题，火星的亮度也经常改变，行踪不定，令人迷惑（升起点在东——东北方位、降落点在西——西北方位之间游走），连远古中国土地上这些猛人们都不得不放弃，给它取名“荧惑星”。萤火是它的颜色，惑则是它的迷惑行为。*\n\n\n\n#### 60年一甲子\n\n　　可是土星的公转周期长达30年。如果想把土星也包含进重点观察名单，必须要找到一个既有效（观察到土星的全部活动）、又经济（最好在人的有生之年能观察到所有对象的重复行为）的周期。\n　　现在，我们知道，中国的一甲子是60年而不是更大的数，说明中国人祖先很早就已掌握最小公倍数的概念和运用。\n　　每一甲子，即60年，我们能看到 日、月、金、水、木、土 六颗星完全重复之前的轨迹。\n　　今天我们说起一甲子，只是一个数字而已，没什么感觉。可是在很长久的历史时期里，这都是一种气魄。不只是一种倾尽全力去追求、维护某种完备性的努力，还有相应的相信这件事儿能办成的气魄。这种气魄最早由一颗眷顾东方的行星逐渐培养起来，但经过数万年的内化，已经深深刻印在中华文明的内核之中，无法抹去了。\n\n　　印度人的经典中，都在追求无尽无边无上的超越人类能想象到的最大智慧的某种智慧。我很尊重他们的专心恒心努力和想象力，可是在我看来他们还缺乏某种气魄。西方人毕业旅行都喜欢去印度寻找灵感，我感觉他们找错了方向，就象修行佛教落入了小乘。当然这里不包括那位被吹成神的乔布斯，他的行事风格表明他有极其强烈的操控欲望，个人性格正好弥补了印度文化上的这种缺憾。而拥有太强烈操控欲望的人反倒不大适合学习中国文化的。\n\n　　公元前2000年建立的古巴比伦王国很意外地也采用了60进制。按道理那里民族复杂，统治者经常更换，不应该出现这么复杂的进位制，毕竟60进制从产生、学习到使用都需要大量的时间和精力，似乎只有在非常稳定、富足的环境下才能产生。古巴比伦和现在的中东土豪们一样，只能满足后者却无法满足前者。不管怎么说，会用60进制的，都hin牛逼！\n　　但是古巴比伦的60进制和中国不一样，他们使用了59个不同的符号来表示1-59（没有0），而中国是地支（12进制）循环5次组成的60。\n　　*猜测：感觉中国的60进制是活的，古巴比伦是呆板的（或者有人说这是因为他们的60进制更早？）。要么中国人最初算12和30的最小公倍数算错成120（天干x地支），后来才修正成60的（修改了天干地支的组合规则，只允许天干和地支分别阳阳、阴阴组合，而不允许阴阳、阳阴组合，去掉一半变成了60进制）？*\n\n　　虽然古巴比伦的消亡同时也带走了中东地区60进制产生之谜的答案，但是那里却有一本书，《圣经》旧约，是唯一一本在中国典籍之外，我能找到一种熟悉的感觉的书。虽然时不时还是会出戏，比如以色列国王的日常工作居然需要审理失窃案，这其实也带来一些亲切感，颇有些中国地方戏曲里“东宫娘娘烙大饼，西宫娘娘剥大葱，皇上顿顿吃白馍，皇后娘娘用金扁担”的影子。排除这些小事件，完全看不出这本书是在讲一个历史上最强盛时期也只在中东几十小国中处于中游的一个国家，整部书有一种宏大的大国气魄，很有内个味儿——一种读我泱泱中华古籍的感觉，难怪它能成为数个宗教都共同承认的经典。\n　　*刚刚写了“唯一1本”，就又想到另一本书，也有读中国典籍的感觉，但不是因为它的气势，而是儒道般的言论。这第二本书是200多年前米国某开国元勋的自传。我算它文明交流的产物了，后边有机会会提到。*\n\n\n#### 5进制\n\n　　因为60和12之间的倍数关系，5变成一个很重要的数——这个数自古就和运势相关，这其实是60带来的红利。60是从天文观测得到的数字，天生就带着预测命运的神秘色彩，和60有关的数字也跟着沾光。\n　　5进制的来由，其实更多的和生命有关，而并非天文观测。\n　　人手有五指，脚有五趾，头有五官，体有五感，本来就和人类自身的生命息息相关（现代基因研究显示，连DNA最基本单元脱氧核苷酸的结构也是五边形的，而且含有5种元素），现在上天又在冥冥之中显示出和5之间有所关联。不知道我们祖先有没有油然产生一种天人合一的感悟。\n　　这些早期因素综合起来，向5赋予了命运的含义。\n　　于是拥有道行的人，用5根手指掐指一算，才有可能能够算出你的运势——神秘的东方道教秘术。（因个人经历我对此既不肯定也不否定。）\n　　五进制影响深远：军队又称行伍，说话要一五一十，算盘横栏上方每颗珠子代表5（3下5除2甚至超脱数学，代表了一种干脆利落的行为模式）。\n\n## 5、6、7，东西方做出选择，文明开始分支\n\n　　在远古的东西方，所有人类都认为，有一个神秘数字，一旦超过它，事情就会发生变化。而且很明显远古时的全球人类是有交流的，大家很好地达成了共识，这个神秘数字就是**6**，东西方同时认为它就是那个由量变导致质变的数字，包括后来由6发展出来的12。\n　　易经所有卦象的第六爻通常预示着一个新境界。\n　　上帝花了六天创造出一个新世界。\n　　这个世界有六道轮回。\n　　埃及最早的金字塔是六层阶梯形的——六级梯形金字塔。\n\n　　不过，同样面对变化，东西方却分别做了不同的选择。\n　　西方倾向于未来——7，变化之后的数字。\n　　而东方倾向于现在——5，变化之前的数字。\n　　这种选择隐含了当年原始人的一些生存状态。西方人祖先觉得日常生活充满不确定性和危险，所以宁愿放弃现在而憧憬未来；东方人祖先生活足够稳定富足，所以宁愿抓住现在不放手。\n\n　　西方选择7后，5和10进制就用得少了，直到后来中国通过印度将10进制传到中世纪的欧洲（1202年，费波那契写《计算之书》，但当时影响不大，再过200多年后随着印刷术的扩散，才在欧洲开始流行）。\n　　中国选择5后，7进制也用得少了，但貌似影响并不大。只是近代从西方引入星期的概念，才在很大程度上影响我们的作息规律。\n　　——按我个人理解，人类作息，最好还是采用与生命关系更密切的5或10进制。\n　　不知道元芳会怎么看？\n\n　　西方虽然选择憧憬未来，却认为变化后事情会向坏的方向发展。这种基础认知导致了古代西方的悲剧意识，在古希腊表现得尤其明显。\n　　但我们的祖先很有意思，他们并不规定这种变化是好还是坏——古人认为“七”会由阳转阴，但阴阳本身不分好坏，纯粹只是变化而已，好坏在于时机和你的应对。这也是东西方一个显著的不同之处。\n\n　　选择5还是7，这种差异非常细小，甚至在易变的当代都不算什么事，今天做了个选择明天退货或者换一下就是。但是远古的人类每个决定都是关系种群存亡的大事。严酷的生存压力已经让他们培养出习惯，对于部落集体或首领做出的选择，会象当代的军规一样，非常慎重地传承下来。细节上的差异，将在未来几千年内，默默地影响着东西方不同的文明进程。\n\n　　《左传》有云：“国之大事，在祀与戎。”\n　　人类祖先从自身和天文观测中发展建立起来的早期数学系统，就这样不知不觉中影响着国之大事。\n\n　　比如今天的5G部署，只有中国运营商比如中国电信选择了选项3x（直接上全新的5G设备），因为梦想更大；而全球很多领先运营商都宣布支持选项3系列（尽量重用旧的4G设备），以实现最初的5G NR部署。\n","tags":["祖先","天文","数学","命运"],"categories":["人文"]},{"title":"远古人类进化","url":"/blog/human/-undefined.html","content":"#### 远古人类，至少已经是几十万年前的事情，和现在的我们有毛线关系？\n\n#### 远古历史迷雾重重。一旦了解了当年的人类是在怎样的环境下，凭借哪些天赋、通过怎样的过程、手段最终达到这颗星球万物之灵的统治地位的，就有可能帮助我们回答下面这些问题：我是谁？我从哪里来？怎样来？最重要的是，会不会在最得意忘形的时候，我们突然遭遇灭绝事件，或被另外一个物种取代？\n\n&nbsp;\n&nbsp;\n\n## 智人不是好人，却是多种“人类”中的唯一幸运儿，幸存原因很可能是因为不够理智\n　　人类进化，就是人类从一种现在已经灭绝的灵长类动物，发展到地球统治者的过程。从生态学角度看，我们现代人类是智人，是一种具有文化、直立行走的物种，生活在地面上，很可能最早在约315,000年前在非洲进化。\n​　　现在的我们，是许多动物学家所称的人类部落Hominini中唯一还活着的成员，但是有大量的化石证据表明，我们的祖先智人（英文“Homo sapiens”，拉丁文“wise man”）出现之前数百万年，地球上就已经有其他人类，例如地猿、非洲南方古猿和同属Homo种的其他人类。\n​　　是的，不算第一个智人出现之前的那些在生物学上已经可以被称为人类的物种，光是智人自己，就还有一系列以英文“Homo”开头的生物学上同种的兄弟姐妹。但现代人很干脆地只有智人这一个祖先，“Homo”家族其余人种都没有后代存活到现在。\n​　　当时，这些古人类因为很近的亲缘关系，相互之间并没有产生完全的生殖隔离，这使得现代人携带有极少量的其他古人类的基因。就算几十万年前，我们的直系祖先智人出现之后，也和至少一种其他人类共存过一段时间，现在称那种人类为穴居人或尼安德特人（Neanderthals 或 H.neanderthalensis）。\n​　　比如，2017年3月3日《科学》杂志发表题为《中国许昌出土晚更新世古人类头骨研究》的论文称，人类演化研究取得突破性进展：10多万年前生活在河南省许昌市灵井遗址的“许昌人”，可能是中国境内古老人类和欧洲尼安德特人的后代。\n![尼安德特人](/img/2020/homo_sapians/博物馆里的尼安德塔人蜡像.jpg \"尼安德特人\")\n​　　　　*博物馆里的尼安德特人蜡像*\n\n　　最早的古人类化石只在非洲有发现，暂时大家认为智人之前的早期人类统一从非洲起源，然后才逐步扩散到其他地方。\n　　当时交通不发达，那么这些古人类，是不是简单地独立出现、占块地方独立生活、再独自静悄悄地灭绝，而相互间没有联系的呢？非也。通过化石上残留基因物质分析，至少非洲的原始人，他们从190万年前开始，有过至少三次大规模迁徙出非洲的行动。\n　　前两次可能失败了，但这些非洲古人类中的探索者和迁徙途中遇到的“土著”交流过程中保留了少量“土著”基因，然后有部分人类留在当地，若干万年后变成后来者眼中的“土著”，大部分又迁回非洲，但带回去一些杂交的基因，混入非洲原有种群中继续发展若干万年，等待再次迁徙。\n![走出非洲](/img/2020/homo_sapians/出走归来.jpg \"走出非洲\")\n\n　　直到大约12万~8万年前，进入智人时代的人类第三次迁出非洲行动才真正成功。\n\n![人类世系](/img/2020/homo_sapians/人类血统.jpg \"智人和其他人类\")\n​　　所有这些早期人类，先后都消失了。大约两万四千年前，最后一支有别于智人的人类，尼安德特人，也从地球上消失了。目前基本都认为是后来新出现的人类灭绝了之前出现的人类，而尼安德特人无法推诿地应该是被智人灭绝的。从生存资源上看不出必须要彻底消灭那些种族的原因，现在的猜测是，我们的祖先不是什么好人，不知出于什么原因，竟然将所有异族全部灭绝了。\n\n![头骨比较图](/img/2020/homo_sapians/大猩猩、直立人与智人头骨的比较图.jpg \"头骨比较图\")\n​　　​　　​*大猩猩、直立人与智人头骨的比较图，主要区别在脑容量*\n​　　我们一直以为人类是靠智慧才得以统治地球的，因为我们脑容量够大。化石证据也显示，后期出现的人类，脑容量比前期出现的人类更大，这样优胜劣汰下才能灭绝更早期的人种。可是，尼安德特人却是个例外，他们明显比同期智人脑容量更大、文明程度更高，而且身体更强壮、四肢更发达，不管从智力还是体力上，人类看起来都只有被尼安德特人吊打、反杀的命运。智人和尼安德特人10万年前的第一次相遇也证明了这个结论，可是诡异的是，短短1万多年后，8万年前智人和尼安德特人再次交锋，这次智人就大获全胜。相差1万年的化石看不出差别，提供不了任何“科学”解释。\n\n　　唯一的解释，只能归功于人类的“相对弱智”。\n​　　尼安德特人也是源于非洲，但是他们更早地到达了欧洲。尼安德特人在早期进化过程中，进化的速度和智人应该不相上下，但是在欧洲的日子里，他们进化的速度明显减慢，从他们使用的工具来看，在几万年的时间里，没有明显的改进。尼安德特人以肉食为主，他们发明了长矛捕猎和围猎的方式，但是他们始终没有发明弓箭。在智人到达欧亚大陆之前，他们是欧亚大陆的主人，他们过着相对悠闲的生活，并且开始懂得用贝壳装饰自己。\n​　　尼安德特人作为一种成功的进化者，文明程度比智人高，生存环境好，相互之间没有争斗。而作为被迫走出非洲寻找新的生存地的智人，不得不一直处于战斗中。不仅仅是和猛兽争夺食物这种体力活动，智商相对较低、不够理智的智人应该也没办法彻底消除同类之间的争斗（其实现在也没什么改善，想想两次世界大战），这种智慧同类间的争斗比从虎口夺食的挑战性要危险得多，必须要提高群体组织能力、发挥出群体战斗力，才能占据上风。由此智人的组织能力在一万年时间内迅速发展起来，原地踏步的尼安德特人个体武力值哪怕满分，哪怕掌握有对付猛兽的群体围猎级别的简单合作能力，也不是军队化的智人部落对手，败下阵来也就不足为奇了。\n​　　对于尼安德特人族灭的这段历史，陈虎平老师的微博总结得很有深度——“make yourself uncomfortable！演化天性让你衣食无忧后就歇着。如果同辈一般，你也好不到哪里去。在微博上泡着、看着、评论着，舒服得要死。只有市场突然改变，或经常遇到牛人，让你不爽、无助、心酸，你的原始能量才会重启，重新想办法、找出路、做产品、拼市场。人都是被逼出来的。没人例外。”\n\n\n## 智人灭绝了多少物种？90%的大型动物被智人灭绝（包括所有其他人种）\n\n　　在几万年前，智人开始学会了交流思考，理解能力摆脱了100%实物环境的限制，学会提出一些虚拟的东西，并且相互之间还可以理解对方的意思。现在的传说都是因此而来的。\n　　大约7万年前，智人成功掌握了火，这又是一大重要的突破。当时其他物种并不知道火的威力。掌握火之后，智人学会了直立行走，学会了制作工具，甚至学会了航海。\n　　智人凭借这些在其他物种眼里莫名其妙的东西，甚至穿过了海洋来到了澳大利亚大陆。智人来到这个不一样的地方觉得十分神奇，并且开始了自己的屠戮之旅。\n　　当时全澳大利亚超过90%的巨型动物，都从历史上消失，澳大利亚的整个生态系统重新洗牌，这也是澳大利亚生态系统，数百万年来最重大的一次转型。\n　　大约在12000年前，智人们无意之中，从俄罗斯穿过白令海峡，来到了阿拉斯加，从而正式进入了美洲大陆。\n　　按照历史进程来看，几乎智人迁移到哪里，哪里的动物就要遭殃。\n　　在这个期间，地球的大约200属大型兽类最终只剩100属左右，这个时候智人甚至还没有发明文字和铁器。\n　　这实实在在地证明智人果然不是好人。我们勉强聊以自我安慰的是，假设换成任何另外一支人类崛起，结果也不会好到哪里去，这说明我们并不是唯一的坏人，只是坏人族群中漏网幸存下来的一支。人类，就是地球生物，尤其是大型生物的天敌。\n　　中国大地不愧地大物博之名，在智人发展的早中晚各个时期，都能找到相应的化石。其中，柳江人、资阳人、河套人以及我们历史课本上非常出名的山顶洞人，都属于晚期智人。这个时期，现代意义上的三大人种（蒙古利亚人种——黄种人，尼格罗人种——黑种人，欧罗巴人种——白种人）已经开始形成，人类文明步入了旧石器时代晚期。\n\n　　这里提一下《人类简史》。\n　　不可否认这是一本好书，值得一看，但也仅此而已，不要把里面的话当成金科玉律。比如里面的基本观点之一，人类是靠讲故事来发展的，读下来让我们感觉似乎能说会道夸夸其谈画大饼非常重要，重要到成为种群发展的基本前提，不会说话的人就只能苟延馋喘苦苦度日。作者那么理解是有他自身宗教信仰方面的原因，《圣经》里就认为有能力的人一定也能说会道，这有利于传教。这种理解已经被西方人看作理所当然，但我们不必当真。\n　　因为除了讲故事，中国人还有一个发展手段，“做”。\n　　没错，哪那么多废话，干就完了。\n　　在中国语境里，能说会道可不是什么好词，人没忽悠到，反倒可能让别人提高了警惕。所以很多真正能言善辩之辈反倒表现得温良恭俭让，比如，据记载，中国远古的领袖都是在关键时刻“做”对了事情，才被大家认可坐稳领袖位置的。仅在某些关键时刻，他们才会出来讲讲故事，平时表现得越低调越成功。\n　　默默干事，让中国人在过去几千年的大部分时间里活得都比其他国家好，但也很辛苦。（关于“辛苦”程度，没法量化，所以也没法横向比较同期其它国家国民的辛苦程度。唯一能确认的，就是所有国家百姓都认为自己很辛苦）\n　　鼓励说还是鼓励做，在于统治者面对的对象。能说会道的人是少数，但一个这样的人就可能大范围地鼓动来一批信徒，所以各种宗教都选择了鼓励“说”。相反，只要身体健全的人就能做事，所以对于世俗国家来说，鼓励“做”显然才是增加国民财富应有的做法。\n　　理想情况下，既能讲故事，又能干，那就无敌了。只是恐怕绝大多数人都无法做到。\n\n\n## 达尔文没说过“人是猿的后裔”。只能确定智人这个祖先，还没有清晰完整的进化链\n\n　　英国博物学家查尔斯·达尔文（Charles Darwin）出版了他的巨著《物种起源》（1859年）和《人类后裔》（1871年）。但与大众普遍以为的不同，达尔文从未宣称“人是猿的后裔”。从理论上讲，人类和猿类应该有一个共同的祖先存在于数百万年前。这个祖先物种并不是某一串联谱系链条上的“缺失环节”，而是一个向不同谱系发散的分支节点。举个例子，比如远古时某个灵长类物种生下一对子女。这对子女看不出什么差别，但是某些隐含特征和后来的生存环境使这对子女发生分化，儿子成为猿类祖先，而女儿成为人类祖先。这个著名的虚构故事中，作为人类祖先的这个女儿名叫Lucy。现实中，这种古老的灵长类动物尚未被鉴定，也可能永远无法确定，因为即使在现代人类自身的谱系中，化石的关系仍不清楚。\n​　　虽然从基因上，我们可以确定现存所有人类都是智人这个唯一物种的后代，并含有少量其它古人类基因，比如2010年基于尼安德特人基因组草图的研究结果发现，除非洲人之外的欧亚大陆现代人均有1%∼4%的尼安德特人基因成分贡献，但现代人类自身的谱系关系无法得到一个一致同意的结果，我们还不能清晰地将自身基因完整地按时间和物种顺序串联起来，一直链接到智人这个祖先。\n​　　这种不确定性，使得人类及其幸存者智人的出现，都显现出一些突发性和偶然性的特征，给各种假说提供了丰富的养料。这些未知也正是引导科学家继续探究下去的动力之一。\n","tags":["人类","进化","幸存者","物种灭绝"],"categories":["人文"]},{"title":"虚拟机与容器","url":"/blog/research/virtualization-undefined.html","content":"\n# 虚拟机Virtual Machine\n\n虚拟机（VM）是用于构建虚拟化计算环境的技术。它们已经存在很久了，被认为是第一代云计算的基础。\n简而言之，虚拟机是物理计算机的仿真。VM可让一台计算机看似多台独立机器，可运行多个相同或不同的操作系统。 VM通过使用称为管理程序的轻量级软件层与物理计算机进行交互。 虚拟机管理程序可以将虚拟机彼此分开，并给它们分配处理器、内存和存储。\n\n## 管理程序 hypervisor\n没有hypervisor，就不可能有虚拟化。系统管理程序或虚拟机监视器是使多个操作系统能够并行运行的软件或固件层，所有这些操作系统都可以访问相同的物理服务器资源。 系统管理程序协调并分离可用资源（计算能力，内存，存储等），并根据需要将分离组合而成的各部分分配给每个虚拟机。\nhypervisor虚拟的是硬件资源。\n![VM](/img/2020/build_service/VM.jpg \"VM\")\n虚拟机架构示意图\n\n## 虚拟机的一些限制：\n1、资源消耗。由于每个VM都包含一个OS和该OS所需所有硬件的虚拟副本，因此VM需要大量的RAM和CPU资源。\n2、由于虚拟副本和所需资源的增加，虚拟机的软件开发生命周期更加复杂。\n3、在公有云、私有云和传统数据中心之间移动虚拟机可能是一个挑战。\n\n\n# 容器Container\n\n容器是一种更轻量，更敏捷的虚拟化方法。容器不打包整个虚拟机，而是将运行某段软件所需的一切打包在一起。容器包含所有应用程序、其依赖项、甚至包括操作系统本身。 这使应用程序几乎可以在任何地方运行——PC、传统的IT设备或云。\n容器虚拟化的是操作系统（OS）。简而言之，它们利用操作系统的功能来隔离进程并控制进程对CPU、内存和桌面空间的访问。\n容器也已经存在了数十年，但是普遍的共识是，现代容器时代始于2013年Docker的引入。\n![Container](/img/2020/build_service/Container.jpg \"Container\")\n容器架构示意图\n\n## 容器与微服务架构\n容器很适合用来部署微服务架构组件。\n下面是我们（练手）将一个原来在虚拟机中部署的普通编译发布服务改造成微服务架构，然后换用容器部署的例子：\n![Before](/img/2020/build_service/Pre-microservice_AzureKube.png \"Before\")\n改造前，实现服务的各部分软件按一个整体(monolith)实现\n\n![After](/img/2020/build_service/Post_microservice_AzureKube.png \"After\")\n改造后，服务由一堆时髦的微服务组成\n\n既然有docker，和它形影不离的**kubernetes**当然也不能少，用它配置个邮件服务：\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emailservice\nspec:\n  selector:\n    matchLabels:\n      app: emailservice\n  template:\n    metadata:\n      labels:\n        app: emailservice\n    spec:\n      terminationGracePeriodSeconds: 5\n      containers:\n      - name: server\n        image: xxxxxx/emailservice:v0.2.0\n        ports:\n        - containerPort: 8080\n        env:\n        - name: PORT\n          value: \"8080\"\n        - name: DISABLE_PROFILER\n          value: \"1\"\n        readinessProbe:\n          periodSeconds: 5\n          exec:\n            command: [\"/bin/grpc_health_probe\", \"-addr=:8080\"]\n        livenessProbe:\n          periodSeconds: 5\n          exec:\n            command: [\"/bin/grpc_health_probe\", \"-addr=:8080\"]\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: emailservice\nspec:\n  type: ClusterIP\n  selector:\n    app: emailservice\n  ports:\n  - name: grpc\n    port: 5000\n    targetPort: 8080\n```\n\n至于monolith和microservice的差异和好处，感觉不大明显，维护起来都很方便。\n\n## 容器技术的一些限制：\n\n1. 特定主机上的所有容器必须设计为与主机同一类型的OS上运行。基于不同操作系统的容器将需要不同的主机。\n2. 由于OS在容器间是共享的，OS内核安全漏洞会对主机上的所有容器造成威胁。\n第2点可以用enclave技术将风险降低。\n\n写到这里，发现需要介绍点安全相关内容。这个领域说起来和所有人都有关，但其实大多数人却不感兴趣。安全是个很深的领域，绝大多数研发活动都在软件算法上。不过前几年幽灵和熔断事件闹得很大，下一篇就介绍点芯片安全相关的简单内容吧。","tags":["silicon","virtualization"],"categories":["存疑"]},{"title":"PCIe Retimer & Redriver","url":"/blog/research/PCIeRetimerRedriver-undefined.html","content":"\n# 起源\n\nRetimer 和 Redriver是从PCIe 3.0开始引入的。这两种卡通常用在服务器和存储系统中，用来支持更长的物理通道。目前PCIe4规范正在完善，PCIe5规范也已发布，面对高速连接方面的新挑战，这些扩展工具将如何堆叠起来？\n\n## Redriver\nRedriver是一种大多数为模拟信号的扩展设备，旨在增强信号的高频部分，以抵消由互连模块（中央处理器（CPU）封装，系统板，连接器等）引起的与频率相关的衰减。 Redriver的数据路径通常包括一个连续时间线性均衡器（CTLE），一个宽带增益级和一个线性驱动器。 另外，Redriver通常具有按设定阈值检测输入信号丢失、和输出信号接收器（output receiver，就是一个把输出的差分信号重新接收/镜像回来的反馈电路，用于控制）检测功能。 图1给出了典型的Redriver框图。\n![Redriver](/img/2020/Retimer_and_Redriver/Redriver_block_diagram.jpg \"Redriver\")\n图1：Redriver框图\n\n## Retimer\nRetimer是一种可识别PCIe协议的模拟/数字混合信号设备，能够完全恢复数据，提取嵌入式时钟并使用干净的时钟重新传输数据的新副本。 除了在Redriver中也在使用的CTLE和宽带增益级之外，Retimer还包括时钟和数据恢复（CDR）电路，判决反馈均衡器（DFE）和发送（Tx）有限冲激响应（FIR）驱动器。 有限状态机（FSM）和/或微控制器通常管理CTLE、宽带增益、DFE和FIR驱动程序的自动适配，并实现PCIe的链路训练状态机（LTSSM）。 图2给出了典型的Retimer框图。\n![Retimer](/img/2020/Retimer_and_Redriver/Retimer_block_diagram.jpg \"Retimer\")\n图2：Retimer框图\n\n简单来说，Redriver会放大信号，而Retimer则会重新传输信号的新副本。 图3对此进行了说明，并显示了如何通过Redriver增强衰减的眼图张开度以及如何通过Retimer完全重新生成。 \n![eyeRedriverRetimer](/img/2020/Retimer_and_Redriver/eye_after_redriver_retimer.jpg \"eyeRedriverRetimer\")\n图3：示例，被信道衰减后信号的眼图（左），衰减信号通过redriver后（中），衰减信号通过retimer后（右）\n\nPCIe 4.0正式定义了术语“Retimer”（重定时器），“Redriver”（转接驱动器）和它们的超集“repeater”（中继器），所有这些都属于扩展设备或组件，目的是扩展链路的物理长度。定义是：\nRepeater 中继器：扩展设备的不精确术语。 （此词会引起混乱……请不要使用它！）\nRedriver 转接驱动器：一种非协议可识别的软件透明扩展设备。\nRetimer 重定时器：物理层协议感知、软件透明的扩展设备，形成两个单独的电气链路段。\n","tags":["PCIe"],"categories":["存疑"]},{"title":"Hardware Abstract Layer","url":"/blog/research/HAL-undefined.html","content":"\n# HAL存在的意义\n\n硬件抽象层是介于android内核kernel和上层之间的抽象出来的一层结构。他是对linux驱动的一个封装，对上层提供统一接口，上层应用不必知道下层硬件具体怎么工作的，它屏蔽了底层的实现细节。\n\n它在整个android架构中的位置如下图所示：\n![HAL](/img/2020/android_HAL.png \"HAL\")\n\n传统的linux对硬件的操作基本上在内核空间的linux驱动程序中实现，那么现在为什么要多此一举把对硬件的操作分为HAL和linux驱动两部分呢？而且HAL是属于用户空间，linux驱动属于内核空间。\n其实并不多余，理由是很多的：\n1、Google搭好了HAL的框架，为上层framework通过JNI调用HAL提供了统一的API，硬件开发商或者移植人员只需要按照框架开发即可，无需花费精力在与上层的交互上的实现上，将精力放在HAL层本身的实现上即可。\n2、（更主要的）从商业角度，许多硬件厂商不愿意将自己硬件相关一些核心的东西开源出去，假如将对自己硬件的驱动程序全部放入内核空间驱动程序实现，那么必须遵循GPL协议，是必需开源的。有了HAL层之后，他们可以把一些核心的算法之类的东西的实现放在HAL层，而HAL层位于用户空间，不属于linux内核，和android源码一样遵循的是Apache协议，这个是可以不用开源的。\n\n以上就是HAL层存在的意义。\n\n现在Linux的驱动也有往用户空间转移的趋势。\n","tags":["Android","driver","userspace"],"categories":["存疑"]},{"title":"对预测执行漏洞的一些解释","url":"/blog/tech/精确的-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n这篇内容不敢自己发挥，因为通过这些描述其实可以理解攻击原理，所以本文中术语部分可能有点拗口（已经仔细斟酌但无法消除这种感觉），它们翻译自Intel严谨拗口的官方资料。\n\n\n\n# 精确的预测执行术语\n\n当前用来描述 **预测执行 侧信道（旁道）脆弱性** 的术语 在某些情况下不够精确。新发现的脆弱性用老的弱点来描述（类似熔断、类似幽灵，等等），会导致对它们的操作和影响产生误解。另外，不同含义的技术术语有时还被混用，比如侧信道（side channel）和隐藏信道（covert channel）。\n\n本文目的是介绍一组简明术语，这些术语正在和研究社区协商以达成共识（本文作者声明：请不要真期望协商结果更新）。Intel准备将本文内的术语用在将来的指导文档中，但不保证更新所有已存的指南。\n\n\n# 信道\n\n信道是计算系统中传输或表达信息的任何介质。计算系统中根据上下文，信道有两种：**合法信道** 是系统设计人员计划中为传输信息而规划的，其它所有信道都是 **次生信道**。合法信道的例子包括以太网、共享内存和 进程间通信套接字。资源竞争、CPU cache状态、以及功耗变化，都是次生信道的例子。（作者John本人更倾向用“嫡生信道”和“庶出信道” 来区分这两者——更形象、更不带歧视色彩，但intel恨死后者，显然不准备给它合法身份）\n\n在 **安全威胁模型** 语境中，区分**恶意对手是否正在开发次生信道**的两种方法 经常会有用。如果对手同时控制住了输入和输出，一条次生信道就会变成一条隐藏信道（covert channel）。如果对手不能控制输入，只能读取输出，这条次生信道就是一条侧信道（side channel）。比如，加密算法执行时可能无意中会泄露敏感数据至某条侧信道，而对手此时正在监控这条侧信道的输出。\n\n注意，**合法信道**和**次生信道** 是计算系统的属性，而 **侧信道**和**隐藏信道** 是威胁模型中 描述对手如何利用次生信道的 术语。\n\n\n# 预测执行背景知识\n当代处理器使用乱序执行指令以提高性能。这些乱序执行处理器会“推测”一条分支或一个负载将使用某个数据，在处理器确认推测值正确之前，就会暂时用推测数据提前执行该分支或负载。当执行到该分支（负载）且知道预测值是否正确时，有两种可能的处理方式：\n\n1.\t如果预测执行所用数据正确，依赖于该数据的指令就是有效的，它们可以退出。意味着它们的结果在架构上可以被程序见到并访问了。\n\n2.\t否则，依赖于该数据的指令无效，它们必须被压出(squashed)，意味着结果不会提交给架构上运行的程序。这些指令被称为暂驻者（transient）。随着暂驻者被挤压出去，处理器可以用正确数据继续执行。\n\n![1](/img/2020/prediction_exe/1.png \"1\")\n图1：演示分支预测的示例：>表示非暂驻指令；*表示暂驻指令。\n\n虽然暂驻指令不会提交给架构上运行的程序，微架构处理器状态仍会受暂驻指令的影响。比如，如果暂驻指令试图加载不存在于任何处理器cache中的数据，相应的数据就会被加载进处理器cache。这个cache的状态就形成一条次生信道。这条信道的数据通过一些分析技术可被观察到，比如“flush+reload”或“prime+probe”测量cache访问延时。\n\n\n# 瞬态执行攻击\n\n瞬态执行攻击 利用 微架构暂驻指令的侧信道，允许恶意对手访问 架构访问控制机制通常会禁止访问 的信息。为成功调用瞬态执行攻击，对手必须：\n1.\t访问受害者的秘密；\n2.\t通过隐藏信道传输该秘密；\n3.\t从隐藏信道接收到该秘密。\n\n前两步合称泄露工具（disclosure gadget）。注意，当对手发现了潜在的次生信道，并控制了它的输入输出，该次生信道 就会充当 隐藏信道（covert channel）。\n\n瞬态执行攻击可依据其对“基于硬件的保护功能”的影响来分类。一个硬件保护领域包括 硬件执行访问控制机制定义的保护范围内的代码和数据，比如特权等级（ring）、页表、保护密钥等。领域的例子包括处理器、SGX飞地（一种intel推出的虚拟机保护机制）、虚拟机、和ring0操作系统代码。领域还可以是通过网络、总线或其它硬件接口相连的机器或设备。网络、总线上传输的内容组成了合法信道，其它可测量的传输属性（比如延迟）形成次生信道。\n\n一个瞬态执行攻击的特征 由 泄露工具和受害者/对手 领域之间的 关系 来描述：如果泄露工具在对手领域中，这种瞬态执行攻击就是“领域旁路攻击”。泄露工具在受害者领域中，就是“跨领域攻击”。如果泄露工具运行在受害者机器上由对手控制的沙箱中，就是“领域内攻击”。下面章节将详述这三种攻击。\n\n\n# 域旁路（Domain-Bypass）瞬态执行攻击\n\n![2](/img/2020/prediction_exe/2.png \"2\")\n图2 剖析域旁路瞬态执行攻击：蓝框表示数据，红框表示受害者代码，箭头表示被攻击的“秘密”的数据流\n\n在瞬态执行攻击中，对手执行硬件访问控制相关的暂驻（瞬态）指令，以获许访问超出他自身领域范围的秘密。这个瞬态指令段还必须包含发送器，比如用以将机密编码到CPU cache态的内存访问。非暂驻接收码 通过使用cache分析技术比如写后重新加载（Flush+Reload），可以恢复机密。\n\n作为特例，考虑恶意数据高速缓存加载（熔断）。对手的领域是个ring3应用，受害者的领域是操作系统内核（ring 0）。当对手试图访问共享相同虚拟地址空间的内核内存，暂驻指令会允许读内核数据，并在由硬件执行的权限检查做出判断之前就把它传送出去。领域旁路暂驻执行攻击的其它例子还包括微架构数据采样（MDS)和层1终止失败（L1TF，intel CPU在页表入口检查的时候，不等检查结果就提前将虚拟地址转换成物理地址，并将物理地址的内容读入到L1 data cache中。L1TF和中文语境很象，意思是等到发现页表入口不对想终止读取的时候，已经拦都拦不住了）。\n\n\n# 跨领域暂驻执行攻击\n\n![3](/img/2020/prediction_exe/3.png \"3\")\n图3：剖析跨域瞬态执行攻击：蓝框表示数据，红框表示对手代码，橙框表示被对手操纵的受害者代码，箭头表示攻击中的机密信息数据流\n\n一次跨领域瞬态执行攻击要求对手在受害者域中找到一个披露小工具，在它执行瞬间，可以临时访问并传输秘密至隐藏信道。\n\n跨领域瞬态执行攻击成功加载的难度通常是最大的，因为对手很难构建披露小工具。关键在于在已有的受害机程序中发现一个在被镇压之前可以成功地临时访问并传输秘密的披露小工具。如果对手在ring3态，其它进程的噪声会大大削弱隐藏信道的可靠性。与受害者同步（按踩点+窃取的要求）对于ring3态的对手也是一个挑战。\n\n一个跨域瞬态执行攻击的例子是 分支目标注入(Spectre variant 2)，一个恶意的ring 3 应用（对手）训练一个与另一ring 3应用（受害者）共享的分支预测器，以预测到对手选择的内存地址。目标地址可以是一个抢在分支误预测处理之前运行，能够临时访问内存并传输秘密的披露小工具。\n\n\n# 域内瞬态执行攻击\n\n![4](/img/2020/prediction_exe/4.png \"4\")\n图4：剖析域内暂驻执行攻击：蓝框是数据，红框是攻击者代码，箭头表示攻击过程中秘密数据流动方向\n\n一次域内暂驻执行攻击可让对手规避掉基于软件的访问控制，访问到处于同一域内的秘密。比如，Javascript程序尝试随机访问一个数组对象时，该访问将接受边界条件检测，这可能会导致某个条件分支的执行。如果程序尝试翻墙访问——但是分支预测以为该程序处于墙内——访问和传送指令会被允许暂时执行，直到误预测的这段代码跑到头。这个例子就是沙箱内的软件对它域内进行的一次边界检查绕开攻击（spectre变种1）。\n\n图4试图表达域内暂驻（瞬时）执行攻击，尽管可能存在其它变体，例如，对手控制的接收方可能在本域的另一个沙箱中，甚至位于另一个域。除了软件沙箱，基于语言的加密或其它软件错误隔离技术也可用来隔离同域内的软件。这些方法也采用了基于软件的访问控制，可能会被瞬态指令所绕开。\n\n\n# 结论和启示\n\n这种精炼的术语将有助于简要传达新发现和现有漏洞的影响，从而使软件开发人员受益。例如：\n• 如果漏洞被描述为具有域旁路影响，那么通常需要做硬件迁移，对操作系统或虚拟机（VMM）进行打上uCode补丁和/或软件更改。通常不需要对应用程序进行软件更改。\n\n• 如果漏洞描述为具有跨域影响，则可能需要对应用程序、OS或VMM代码进行软件更改以缓解漏洞。这些软件更改可能会使用或新推出或已有的处理器功能，来防止推测，或隔离不同模式间的分支预测。开发人员还应考虑到，跨域瞬时执行攻击通常比其他种类的瞬时执行攻击更难发动。因此，开发人员在决定如何减轻软件负担时应使用自己的判断力（例如，是自动插入LFENCE还是仅在确定为容易受边界检查绕过攻击的位置插入LFENCE）。\n\n• 如果漏洞被描述为具有域内影响，则使用沙盒技术的受影响软件可能会受到攻击。有关更多信息，请参考《深入托管运行时》。\n\n一致使用本文中概述的术语将使广泛的安全研究界更容易协作以识别未来的潜在威胁和缓解措施。\n\n\n# 瞬态执行分类\n\n| 已披露的 | 域内 | 跨域 | 域旁路 | 缓解 |\n| :--: | :---: | :--: | :--: | :--: |\n| 变种1：边界检查绕过 (Spectre v1) 包括边界检查绕过存储 | X | X |   | 关于“域内”的范围，可将下面提到的沙箱一词替换成其它技术（比如，进程隔离，保护密钥，等等）；替代沙箱的增强技术这里有讨论。通常可通过预测器隔离或在受害者中部署防御性软件技术（例如SLH，LFENCE等）来缓解跨域攻击，以防止小工具被利用。 |\n| 变种2：分支目标注入 (Spectre v2) | X    | X    |      |      |\n| 变种4：投机性存储绕过 (Spectre v4) | X    | X    |  |      |\n| 加载值注错 (所有类型) | X    | X    |      |      |\n| 投机性SWAPGS |  | X |  |  |\n| 变种3: 恶意数据缓存加载（熔断） |  |  | X | 需要更新硬件或在域转换时更新状态来缓解域旁路瞬态执行攻击 |\n| 变种3a: 恶意读取系统寄存器 |  |  | X |  |\n| 微架构数据采样 |  |  | X |  |\n| TSX异步中止 |  |  | X |  |\n| 向量寄存器采样 |  |  | X |  |\n| 层1终端故障 |  |  | X |  |\n| L1D逐出采样 |  |  | X |  |\n| 懒惰的FPU |  |  | X |  |\n| 探听辅助L1D采样 |  | See footnote 8 | X |  |\n\n","tags":["prediction"],"categories":["tech"]},{"title":"缓解熔断与幽灵威胁的3种新的执行预测控制机制：IBRS, IBPB & STIBP","url":"/blog/tech/meltdown-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n2018年初，meltdown和spectre闹得沸沸扬扬，我也参加了相关task force。\n这两种漏洞无法根除，只能缓解。官方紧急推出了三种新的执行预测控制机制，本文试图稍微解释一下它们。\n\n\n# 间接分支有限预测\nIndirect Branch Restricted Speculation (IBRS)\n\n间接分支有限预测（IBRS）是一种非直接分支控制机制，就象它的名字，用于限制间接分支的预测。访问CPUID寄存器，当EAX=7H,ECX=0时，EDX[26]返回 1，说明该CPU支持IBRS。\nIBRS可以帮助降低BTI和SSB的风险。它可以与IBPB配合以覆盖更多场景。\n\n基本支持\n支持IBRS的处理器提供如下保障而无需软件特地去使能（enable）它：\n\t• 在SGX保护容器飞地（enclave）中执行的 **非直接近分支** 的预测对象，不会被该飞地之外运行的软件控制。\n\t• 如果系统管理中断（SMI）和系统管理模式（SMM）默认是活动状态，在SMI之前执行的软件不能控制 SMM中在SMI之后执行的**非直接分支**的预测对象。\n\n需要软件使能（用户授权）才能支持\nIBRS给关键软件提供了一种保护**非直接分支预测**的方法。\n如果软件转换成更高特权级的预测器模式后，再将IA32_SPEC_CTRL.IBRS置1，该模式下执行的 **非直接分支的预测对象** 不会被 较低特权级预测器模式下运行的软件控制。另外，当IA32_SPEC_CTRL.IBRS置1时，**非直接分支预测对象** 不会被其它逻辑处理器控制。\n如果软件转换成更高特权级的预测器模式时，IA32_SPEC_CTRL.IBRS已经置1，有些处理器可能会允许之前执行的软件控制这之后的非直接分支预测对象。软件可以规避这种情况，用 IA32_SPEC_CTRL寄存器中的WRMSR来将IBRS位置1，不用理会之前的值，无须事先清0。\nIA32_SPEC_CTRL.IBRS置1不能充分阻止 **近返回预测对象** 使用 从较低权限预测器模式下创建的RSB entry（利用处理器架构预测到返回地址）。软件可以规避这种情况，使用返回栈缓冲（RSB）覆盖机制，紧接着转换到更高特权级预测器模式。\n如果使能了管理模式执行禁止（SMEP）功能，就不必再使用这种覆盖再升权限的机制。SMEP阻止用户模式页代码的执行，即便是预测。在管理模式下，用户模式代码只能将返回地址插入到RSB中，而不能使用管理模式代码页中的返回地址对象。有些不支持SMEP的CPU，OS和应用使用分离的页表，OS页表可以将用户代码映射为不可执行。处理器不会预测执行这些被标记为不可执行的代码。\n使能IBRS不会阻止 软件 控制同样预测器模式下的无关软件的 **间接分支预测对象**（比如，两个不同的用户应用，或两个不同的虚拟机）。这种隔离可以用**IBPB**命令（见本文后面部分）来完成。\n在一个支持intel超线程技术的逻辑处理器上使能IBRS，可能会影响同一个核心内的其它逻辑处理器的分支预测。基于这个原因，软件进入休眠状态（比如执行HLT或MWAIT指令）之前，应该关闭IBRS（通过清除IA32_SPEC_CTRL.IBRS）。在唤醒后，执行任何非直接分支预测之前，再次唤醒IBRS。\n \n增强IBRS\n有些处理器可以通过简单的软件使能增强IBRS并提升性能。\n增强IBRS支持一种“常开”模式，通过设置 IA32_SPEC_CTRL.IBRS 打开一次以后，这项功能就不再关闭了。如果带增强IBRS功能的处理器设置了 IA32_SPEC_CTRL.IBRS = 1，低权限预测器模式下运行的软件 或者其它逻辑处理器 就不能控制 它的间接分支执行的预测对象。\n作为结果，增强IBRS处理器上运行的软件不需要 在每次转换到高权限预测器模式时 用 WRMSR来设置 IA32_SPEC_CTRL.IBRS。这个位置位一次，软件就能有效隔离不同的预测器模式。通过MWAIT或HLT之类指令进入休眠模式之前，软件也不用特意去关闭增强IBRS。\n在带增强IBRS的处理器上，一个RSB覆盖序列可能不能充分地阻止 近返回的预测对象 使用 低权限预测器模式下创建的RSB入口。软件可以在 从用户模式转换到管理模式时 打开SMEP 并且在虚拟机退出时置位 IA32_SPEC_CTRL.IBRS 来阻止这种情况发生。增强IBRS处理器仍支持 仅在打开了SMEP的 OS或虚拟机中 使能IBRS 这种使用模型。为做到这点，这种处理器可以保证当IBRS打开后，VM退出后的客户(VMX non-root模式下的客户端操作)行为不能控制RSB，即便IBRS 在虚拟机退出时刻 仍没打开。\n如果虚拟机客户系统清除了IBRS，虚拟机退出后管理程序会再次打开IBRS，就象仅支持普通IBRS的处理器该做的那样。和IBRS一样，增强IBRS也不会阻止软件 影响 同样预测器模式下运行的间接分支预测对象。这种情况下，软件应该使用IBPB命令。\n\n脚注\n\t1. 不要通过中断来做预测器模式转换。这种方式是个例外，不能充分阻止低权限模式下的软件。\n\t2. RSB覆盖操作是一系列包含 32+以上的近CALL指令，以及和RET指令附近原有的0值不同的非0替代值。\n\n\n# 间接分支预测器屏障\nIndirect Branch Predictor Barrier (IBPB)\n\n间接分支预测器屏障（IBPB），是一种非直接分支预测的控制机制。它创建一个屏障，阻止在该屏障之前执行的软件 控制 该屏障之后 于同一逻辑处理器上执行的软件 的间接分支预测 的预测对象。如果处理器CPUID (EAX=7H,ECX=0 时，EDX[26]返回 1，说明该CPU支持IBPB。IBPB可以帮助降低BTI的风险。\n\nIBPB没有定义新的处理器控制分支预测器的工作模式，不像IBRS（间接分支有限预测）和STIBP（单线程间接分支预测器）。因此，它不是通过IA32_SPEC_CTRL寄存器的某个比特位来使能的。需要时，执行一条软件“命令”就可以了，软件会将 IA32_PRED_CMD寄存器的bit 0置位。这个操作可以通过WRMSR指令修改，或者在虚拟机VMX转换时，从MSR加载区域加载寄存器时完成。IA32_PRED_CMD寄存器是只写的，当你准备将IBPB位置1时，不必提前清0。\n\nIBPB和IBRS配合，可以覆盖一些IBRS无法覆盖的场景：\n\t· 如IBRS的描述中提到的，IBRS不会阻止软件去 控制 同样预测器模式下的无关软件的 间接分支预测对象（比如，两个不同的用户应用，或两个不同的虚拟机）。软件可以阻止这种控制，通过执行一条IBPB命令，改变特定预测器模式下的软件操作的ID（比如，改变用户应用或虚拟机（的ID？））。\n\t· 软件可能选择在特定条件下清除IA32_SPEC_CTRL.IBRS（比如，虚拟机VMX root操作执行时带上CPL=3参数）。这种情况下，软件可以在特定转换时使用IBPB命令（比如，运行一个不受信任的虚拟机后）来阻止较早时执行过的软件 控制 关闭了IBRS的 间接分支预测对象执行序列。\n\n\n# 单线程间接分支预测器\nSingle Thread Indirect Branch Predictors (STIBP)\n\n单线程间接分支预测器（STIBP）是一种间接分支控制机制，用来约束同一个core上的逻辑处理器之间共享它们的分支预测。如果访问CPUID，当EAX=7H,ECX=0时，EDX[27]返回1，这颗处理器就支持STIBP。STIBP可用于帮助降低BTI的风险。\n如间接分支预测（IBP）和超线程技术（HT）描述中提到，同一个core上的逻辑处理器可能共享间接分支预测器，允许一个逻辑处理器 控制 同一个core上另一逻辑处理器的 间接分支预测目标。将IA32_SPEC_CTRL的STIBP位置1，将禁止该core上任一逻辑处理器上的间接分支预测目标代码 被同core上的不同逻辑处理器控制。\n请记住间接分支预测器不会被跨core共享。因此，某一个core上运行的间接分支预测目标代码不会被其它core上运行的软件影响。如果软件运行在不同core上，不必打开IA32_SPEC_CTRL.STIBP（以隔离间接分支预测）。\n不管STIBP是否打开，很多处理器不允许另一逻辑处理器上运行的软件控制 它的间接分支预测对象。这种情况包括没有打开超线程（HT）功能的处理器，这时它不会在 逻辑处理器 之间共享 间接分支预测器。为了简化软件使能和负载迁移，这种处理器可能会显示它支持STIBP功能，且允许使能STIBP。\n一个处理器可能会显示它支持IBRS/IBPB却不支持STIBP，也就是当EAX=7H,ECX=0时，EDX[26]返回1，EDX[27]却返回0。这种处理器，向IA32_SPEC_CTRL寄存器执行WRMSR操作，源操作数的bit 1被置1时，会忽略这个比特（STIBP），不会导致通用保护例外（#GP）。预计在某些情况下，这一事实将简化虚拟化。\n如IBRS概述中所讲，打开IBRS能阻止一个逻辑处理器中的软件操作 控制 另一逻辑处理器执行的间接分支预测对象。因此，如果打开了IBRS，就不用再打开STIBP。\n如果某个core打开了超线程（HT），再打开它的一个逻辑处理器的STIBP功能，可能会影响该core上另一逻辑处理器的分支预测。因此，在执行HLT或MWAIT等指令休眠之前，软件应该关掉STIBP功能（清除IA32_SPEC_CTRL.STIBP）,并且在唤醒后执行任何间接分支之前重新打开STIBP。","tags":["security"],"categories":["tech"]},{"title":"缓存cache，末级缓存LLC 和 缓存一致性","url":"/blog/tech/LLC-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n恕我词汇贫乏后面有几个词一时想不出对应的汉语词汇，为保持一致性，有些词会直接使用英文原词。\n\n没想到还没写完第一句话，就发现需要大堆的名词解释，能忍受的估计都是同行哈哈。\n\n===============================\n\n# 名词解释：\n**cache block 高速缓存块**：    缓存存储的基本单位。可能包含多个字节/字的数据。\n**cache line 缓存行**：    与缓存块相同（case line = case block）。 请注意，这与高速缓存的“Row（行）”不同，那个。\n**cache set 缓存集**：    缓存中的“行（row）”（再罗嗦一下不要和cache line弄混了，应该把case line这个历史名词去掉）。 每组的块数由高速缓存的布局确定（例如，直接映射，组关联或完全关联）。\n**tag 标记（或标签）**：    一组数据的唯一标识符。 由于不同的内存区域可能会映射到同一个块中，因此使用标签来区分它们。\n**valid bit 有效位**：    指示块中数据有效（1）还是无效（0）的信息位。\n**Snoop filter 探听过滤器**: \n当特定缓存块上有总线事件时，所有侦听器（snoopers）都必须侦听总线事务。然后，侦听器查找其相应的缓存标记，以检查其是否具有相同的缓存块。在大多数情况下，缓存没有该缓存块，因为优化良好的并行程序不会在线程之间共享大量数据，这样的缓存依然进行标记查找就没必要了。除了没这个必要，更进一步的，标签查找会干扰处理器对缓存的访问，并导致额外的功耗。\n减少不必要的监听的一种方法是使用探听过滤器。探听过滤器确定窥探者是否需要检查其缓存标签。探听过滤器是基于目录的结构，它监视所有一致性流量，以便跟踪高速缓存块的一致性状态。这意味着探听过滤器知道具有缓存块副本的缓存。因此，它可以防止不具有缓存块副本的缓存进行不必要的监听（因为没有必要又耗电）。\n取决于侦听过滤器的位置，有三种类型的过滤器。一种是位于高速缓存侧的源过滤器，它在相干流量到达共享总线之前执行过滤。另一个是目标过滤器，它位于接收器缓存中，可以防止在接收器核心进行不必要的缓存标记查找，但是这种类型的过滤无法阻止来自源的初始一致性消息。最后，网络内过滤器可在共享总线内部动态修剪相干通信。\n探听过滤器也分为包容性和独占性。包含性探听过滤器可跟踪高速缓存中高速缓存块的**存在**。但是，排他探听过滤器监视高速缓存中高速缓存块的**不存在**。换句话说，包含性探听过滤器中的命中意味着相应的缓存块由缓存保存（来吧，我这里有）。另一方面，排他侦听过滤器中的命中意味着没有缓存具有请求的缓存块(没有，不要再找我了)。\n\n**Mesh 网格**: 英文解释为织物（fabric），您可以想象为经纬纵横的类似于纱布那样的二维阵列，形成全系统范围的互连网格。现在您将纱布里的纱换成电线更贴近一点，里面传递的是总线信号。\n**Tile 磁性贴**：　模块化IP块，可以在大型网格上多次复制。您直接理解为积木块也可以，它是小心调整后设计组合在一起的一组硬件IP，可以批量复制。\n**Core Tile 内核磁性贴**：　一种特定类型的硬件ＩＰ块，它融合了Intel的x86核心。\n**IMC Tile ＩＭＣ（Intel Memory Controller）磁性贴**：　一种特定类型的磁贴，包含了集成的内存控制器\n**Caching/Home Agent (CHA) 缓存/本地代理**: 位于核心磁贴中的一个单元，用于维持磁贴之间的缓存一致性。 CHA还与CMS（ＣＭＳ见下面）交互。\n**Converged/Common Mesh Stop (CMS)　聚合/公用网格停靠站**：　网格停靠站，用于连接磁性贴（Ｔｉｌｅ）和结构（ｆａｂｒｉｃ）\n\n\n\n\n# 正文\n\n最新设计中，缓存IP从CHA IP中分离出来。CHA含有缓存控制器和缓存一致性引擎，管理所有socket上的所有cache。CHA IP是SCF（Scalable Coherent Fabric）IP的一部分，SCF（可伸缩一致性结构）用于支持芯片设计（搭积木时的）结构一致性和即插即用。\n\n缓存IP（cache）是拥有下列功能模块的硬件IP，包括： 末级缓存（Last Layer Cache），探听过滤器（Snoop Filter）【SF又包含本地探听过滤器（LSF）和远程探听过滤器（RSF）】，以及相关逻辑。用于为SCF（Scalable Coherent Fabric）和 CHA IP之间提供数据缓存。\n\n每个数据entry包含数据阵列中的一个高速缓存块（64字节的block or line，这两个词在这里等价，详见前面名词解释部分），该缓存行（cache line，==缓存块）分两笔在两个连续周期中从数据接口CHA发送到LLC。\n\nLLC（末级缓存，Last Layer Cache，在Intel CPU中通常是指第3级缓存）的每个entry保存6种信息：data, tag, state, core valid, 2lm 和 LRU。\n　　tag信息存储在Tag数组中。 \n　　MESI状态和Core　Valid信息存储在StateCV数组中。 \n　　TwoLM位存储在2LM阵列中。\n　　LRU信息存储在LRU阵列中。 \n\n其中MESI就涉及到常说的缓存一致性的问题。\n\n临时还要再加一个名词解释\n**cache coherence 缓存一致性**：系统中存在多个本地缓存时，最终存储在这些本地缓存中的共享资源数据需要保证一致性。当系统中有多个客户端分别维护公用内存资源的在它自己本地的缓存时，数据不一致可能会出现问题，在多处理器CPU中尤其如此。\n\n在下图中，考虑两个客户端都具有先前读取的特定内存块的缓存副本。假设底部的客户端更新/更改了该内存块，则顶部的客户端可能留下无效的内存缓存，而没有任何更改通知。 高速缓存一致性旨在通过在多个高速缓存中维护数据值的一致性视图来管理此类冲突。\n![Cache_Coherency](/img/2020/Cache_Coherency/Cache_Coherency_Generic.png \"Cache_Coherency\")\n\n可见缓存一致性问题通常出现在有内存写入的情况下。有两种方案可以应对：\n\n1. Write Invalidate 写无效\n动作：\n–想要写的CPU，将地址发送到总线，占用总线周期发送一个“写无效”消息\n–所有侦听缓存均使该地址对应的缓存行副本无效\n–CPU写入其缓存的副本（现在假设它也写入内存）\n–现在，其它CPU中任何共享读取都将丢失高速缓存并重新获取新数据。\n\n2. Write Update 写更新\n–想要写入的CPU会获取总线周期并在更新自己的副本时广播新数据\n–所有侦听缓存均更新其副本\n\n请注意，在两种方案中，都假设总线仲裁器可以解决并发写入的问题——任一时间只有一个CPU可以使用该总线。\n\n第二种方案（更新），看起来最简单，最明显，最快，但是：\n–对同一数据的多次写入（无中间读取），若用无效（Invalidate）消息，仅需要在最后一笔写入时更新，但现在用Update机制，每个消息都需要更新。\n–写入多个字节的地址段（通常）位于高速缓存块中的同一块范围内时，若用无效（Invalidate）消息，仅需要一次操作，但若用Update机制，则要做多次更新。\n\n由于（计算机系统常见的）时空局部性原理，上述情况经常发生。\n• 总线带宽是共享内存多处理器中的宝贵财富\n• 经验表明，无效（Invalidate）协议使用的带宽要少得多\n于是下面仅考虑无效协议（Invalidate）的实施细节。\n\n在Invalidate和Update两种方案中，如果知道某个（些）缓存的值是否在别的缓存中有共享（复制），就可以避免发送不必要的消息。\n无效描述假定高速缓存值更新已写入内存。如果我们使用“拷回”方案，则其他处理器可能会在缓存未命中时重新获取旧值。\n我们需要一个协议来处理所有这一切。\n\nMESI就是这样一种实用的多处理器无效协议，该协议试图将总线使用率降到最低。\n• 允许使用“回写”方案——即直到“脏”高速缓存行被替换之前才更新至主存\n• 扩展常用的缓存标签，即无效标签和普通回写缓存中的“脏”标签。\n\n任何高速缓存行都可以处于4种状态之一（2比特）\n• Modified 已修改 ——缓存行已修改，与主内存不同——是唯一的缓存副本。（多处理器“脏”）\n• Exclusive 独占  ——高速缓存行与主内存相同，且是唯一的高速缓存副本\n• Shared    共享  ——与主内存相同，但其他缓存中可能存在副本。\n• Invalid   无效  ——行数据无效（就象在简单缓存中那样）\n\n高速缓存行的状态随内存访问事件而变化。\n事件可能是\n–由于本地处理器活动（即缓存访问）\n–由于总线活动\n-由于监听\n仅当地址匹配时，缓存行的状态才会受到影响\n\n可以通过查看本地处理器的动作来非正式地描述操作\n–读命中\n–读未命中\n–写命中\n–写未命中\n\n正式的MESI操作请看状态转换图。\n\n![local](/img/2020/Cache_Coherency/MESI_local.png \"local\")\n本地访问\n\n![remote](/img/2020/Cache_Coherency/MESI_remote.png \"remote\")\n远程访问","tags":["memory","cache"],"categories":["tech"]},{"title":"x86地址翻译","url":"/blog/tech/x86_Addr_Translate-undefined.html","content":"\n\n下文是站在OS的角度看的地址翻译过程，提到怎样通过页表将虚拟地址转换成物理地址，但没提到页表本身的创建过程。页表的创建是由OS调用BIOS中的address translator模块完成的，因为每一代CPU根据芯片内部模块占用地址空间都会有所调整，CPU厂家（Intel、AMD等）会向OEM、ODM等伙伴提供参考代码，没有必要强记。\n\n# 1、概念\n\n**物理地址(physical address)**\n\n用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相相应。\n——这个概念应该是这几个概念中最好理解的一个。可是值得一提的是，尽管能够直接把物理地址理解成插在机器上那根内存本身，把内存看成一个从0字节一直到最大空间逐字节编号的大数组，然后把这个数组叫做物理地址。可是其实，这仅仅是一个硬件提供给软件的抽像，内存的寻址方式并非这样。所以，说它是“与地址总线相相应”，更贴切一些。只是抛开对物理内存寻址方式的考虑，直接把物理地址与物理内存一一相应，也是能够接受的。或许错误的理解更利于形而上的抽象。\n\n**虚拟内存(virtual memory)**\n\n这是对整个内存（不要与机器上插在某个slot上的那根内存条对上号）的抽像描叙。\n\n它是相对于物理内存来讲的，能够直接理解成“不直实的”、“假的”内存。比如，一个0x08000000内存地址。它并不恰好就是物理地址上那个大数组中（0x08000000-1）那个地址元素。\n\n之所以这样，是由于现代操作系统都提供了一种内存管理的抽像，即虚拟内存（virtual memory）。进程使用虚拟内存中的地址，由操作系统协助相关硬件，把它“转换”成真正的物理地址。\n\n这个“转换”。是全部问题讨论的关键。\n\n有了这种抽像，一个程序，就能够使用比真实物理地址大得多的地址空间。\n\n（拆东墙，补西墙，银行也是这样子做的）。甚至多个进程能够使用同样的地址。不奇怪，因为转换后的物理地址不同。\n\n——把连接后的程序反编译看一下，就会发现连接器已为程序分配了一个地址。比如，要调用某个函数A，代码不是call A，而是call 0x0811111111 ，也就是说，函数A的地址已经被定下来了。没有这种“转换”，没有虚拟地址的概念，这样做是根本行不通的。\n打住了。这个问题再说下去，就收不住了。\n\n**逻辑地址(logical address)**\n\nIntel为了兼容，将远古时代的段式内存管理方式保留了下来。\n\n逻辑地址指的是机器语言指令中，用来指定一个操作数或者是一条指令的地址。以上例，我们说的连接器为A分配的0x08111111这个地址就是逻辑地址。\n——只是不好意思，这样说，好像又违背了Intel段式管理中，对逻辑地址的要求。“一个逻辑地址，是由一个段标识符加上一个指定段内相对地址的偏移量。表示为 [段标识符：段内偏移量]”，也就是说。上例中那个0x08111111，应该表示为[A的代码段标识符: 0x08111111]这样，才完整一些。\n\n**线性地址(linear address)，或也叫虚拟地址(virtual address)**\n\n跟逻辑地址类似，它也是一个不真实的地址。假设逻辑地址是相应硬件平台段式管理转换前的地址的话，那么线性地址则对应硬件页式内存的转换前地址。\n\nCPU将一个虚拟内存空间中的地址转换为物理地址，需要两步：首先拿到需要转换的这个逻辑地址（事实上是段内偏移量，这个一定要理解！）。CPU先利用其段式内存管理单元，将逻辑地址转换成一个线程地址，再利用其页式内存管理单元，转换为最终的物理地址。\n\n这样做两次转换，很麻烦且没必要，因为直接就能把线性地址传给进程。之所以这样冗余，Intel全然是为了兼容而已。\n\n\n\n# 2、CPU段式内存管理，逻辑地址怎样转换为线性地址\n\n一个逻辑地址由两部份组成，段标识符: 段内偏移量。\n\n段标识符由一个16位字段组成，称为段选择符。\n\n当中前13位是一个索引号。\n\n后面3位包括一些硬件细节，如图：\nSnap1.jpg \n最后两位涉及权限检查，本贴中不包括。\n\n索引号，或者直接理解成数组下标——那它总要相应一个数组吧，它又是什么东东的索引呢？这个东东就是“段描叙符(segment descriptor)”，呵呵，段描叙符详细地址描叙了一个段（对于“段”这个字眼的理解，可以把它想像成，拿把刀，把虚拟内存砍成若干段）。这样，多个段描叙符就组成一个数组，叫“段描叙符表”。这样，能够通过段标识符的前13位，直接在段描叙符表中找到一个详细的段描叙符，这个描叙符就描叙了一个段。\n每个段描叙符由8个字节组成。如下图：\nSnap2.jpg \n这些东东非常复杂，尽管能够利用一个数据结构来定义它，只是。我这里只关心一样，就是Base字段，它描叙一个段的起始位置的线性地址。\n\nIntel设计的本意是。一些全局的段描叙符，就放在“全局段描叙符表(GDT)”中。一些局部的，比如每个进程自己的，就放在所谓的“局部段描叙符表(LDT)”中。\n\n那到底什么时候该用GDT。什么时候该用LDT呢？这是由段选择符中的T1字段表示的，=0。表示用GDT，=1表示用LDT。\n\nGDT在内存中的地址和大小存放在CPU的gdtr控制寄存器中。而LDT则在ldtr寄存器中。\n\n\n\n好多概念。像绕口令一样。\n\n这张图看起来要直观些：\nSnap3.jpg \n首先，给定一个完整的逻辑地址[段选择符：段内偏移地址]，\n1、看段选择符的T1=0还是1，知道当前要转换是GDT中的段，还是LDT中的段，再依据对应寄存器，得到其地址和大小。我们就有了一个数组了。\n2、取出段选择符中前13位，查找到相应的段描叙符。这样，它的Base即基地址就知道了。\n3、把Base + offset，就是要转换的线性地址了。\n\n还是挺简单的，对于软件来讲，原则上就须要把硬件转换所需的信息准备好，就能够让硬件来完毕这个转换了。OK。来看看Linux怎么做的。\n\n\n\n# 3、Linux的段式管理\nIntel要求两次转换。这样虽说兼容了，可是却非常冗余。\n对于其他某些硬件平台，没有二次转换的概念，Linux也需要提供一个高层抽象，来提供一个统一的接口。这时的Linux段式管理仅仅“哄骗”了一下硬件而已。\n\n依照Intel本意，全局用GDT，每个进程自己的用LDT——只是Linux对全部进程都使用同样的段来对指令和数据寻址。即用户数据段、用户代码段。相应的，内核中是内核数据段和内核代码段。这样做没什么奇怪的，本来就是个封装形式嘛。\ninclude/asm-i386/segment.h\n#define GDT_ENTRY_DEFAULT_USER_CS        14\n#define __USER_CS (GDT_ENTRY_DEFAULT_USER_CS * 8 + 3)\n\n#define GDT_ENTRY_DEFAULT_USER_DS        15\n#define __USER_DS (GDT_ENTRY_DEFAULT_USER_DS * 8 + 3)\n\n#define GDT_ENTRY_KERNEL_BASE        12\n\n#define GDT_ENTRY_KERNEL_CS                (GDT_ENTRY_KERNEL_BASE + 0)\n#define __KERNEL_CS (GDT_ENTRY_KERNEL_CS * 8)\n\n#define GDT_ENTRY_KERNEL_DS                (GDT_ENTRY_KERNEL_BASE + 1)\n#define __KERNEL_DS (GDT_ENTRY_KERNEL_DS * 8)\n\n\n把当中的宏替换成数值。则为：\n#define __USER_CS 115        [00000000 1110  0  11]\n#define __USER_DS 123        [00000000 1111  0  11]\n#define __KERNEL_CS 96      [00000000 1100  0  00]\n#define __KERNEL_DS 104    [00000000 1101  0  00]\n\n方括号后是这四个段选择符的16bit二进制表示，它们的索引号和T1字段值也能够算出来了\n__USER_CS              index= 14   T1=0\n__USER_DS              index= 15   T1=0\n__KERNEL_CS           index=  12  T1=0\n__KERNEL_DS           index= 13   T1=0\n\n\nT1均为0。则表示都使用了GDT。再来看初始化GDT的内容中对应的12-15项(arch/i386/head.S)：\n        .quad 0x00cf9a000000ffff        /* 0x60 kernel 4GB code at 0x00000000 */\n        .quad 0x00cf92000000ffff        /* 0x68 kernel 4GB data at 0x00000000 */\n        .quad 0x00cffa000000ffff        /* 0x73 user 4GB code at 0x00000000 */\n        .quad 0x00cff2000000ffff        /* 0x7b user 4GB data at 0x00000000 */\n\n依照前面段描叙符表中的描叙，把它们展开，发现其16-31位全为0，即四个段的基地址全为0。\n\n这样。给定一个段内偏移地址。依照前面转换公式。0 + 段内偏移，转换为线性地址。能够得出重要的结论，\n**在Linux下，逻辑地址与线性地址总是一致（是一致，而不是有些人说的“同样”）的，即逻辑地址的偏移量字段的值与线性地址的值总是相等的。**\n\n忽略了太多的细节，比如段的权限检查。\n\nLinux中，绝大部份进程并不使用LDT，除非使用Wine仿真Windows程序的时候。\n\n\n# 4、CPU的页式内存管理\n\nCPU的页式内存管理单元，负责把一个线性地址，最终翻译为一个物理地址。从管理和效率的角度出发，线性地址被分为以固定长度为单位的组，称为页(page)。比如一个32位的机器，线性地址最大可为4G，能够用4KB一个页来划分，整个线性地址被划分为一个total_page[2^20]的大数组，共同拥有2的20次方个页。这个大数组我们称之为页文件夹。文件夹中的每个文件夹项，就是一个物理地址——相应的页地址的对应。\n\n还有一类“页”，我们称之为物理页，或者是页框、页桢的。是分页单元把全部的物理内存也划分为固定长度的管理单位，它的长度一般与内存页是一一相应的。\n\n这里注意到，这个total_page数组有2^20个成员，每个成员是一个地址（32位机，一个地址4字节）。那么要单单要表示这个数组，就要占去4MB内存空间。\n\n为了节省空间，引入了一个二级管理机制来组织分页单元。文字描叙太累，看图直观一些：\nSnap1.jpg \n如上图。\n\n1、分页单元中，页文件夹是唯一的，它的地址放在CPU的CR3寄存器中，是进行地址转换的起始点。万里长征从此长始了。\n2、每个活动进程，由于都有其独立的相应的虚似内存（页文件夹也是唯一的），那么它也对应一个独立的页文件夹地址。\n——执行一个进程，需要将它的页文件夹地址放到CR3寄存器中，将别人的保存下来。\n3、每个32位线性地址被划分为三部份，文件夹索引(10位)：页表索引(10位)：偏移(12位)\n\n根据下面步骤进行转换：\n1、从CR3中取出进程的页文件夹地址（操作系统负责在调度进程的时候，把这个地址装入相应寄存器）；\n2、依据线性地址前十位，在数组中，找到相应的索引项。由于引入了二级管理模式，页文件夹中的项，不再是页地址，而是一个页表的地址（又引入了一个数组）。页地址被放到页表中去了。\n3、依据线性地址的中间十位，在页表（也是数组）中找到页的起始地址；\n4、将页起始地址与线性地址中最后12位相加，就得到最终我们想要的物理地址。\n\n这个转换过程，应该说还是很easy的。\n\n全部由硬件完成，尽管多道手续，可是节约了大量内存，还是值得的。那么再简单地验证一下：\n1、这种二级模式是否仍可以表示4G的地址；\n页文件夹共同拥有：2^10项，也就是说有这么多个页表\n每一个页表对应了：2^10页\n每一个页中可寻址：2^12个字节。\n还是2^32 = 4GB\n\n2、这种二级模式是否真的节约了空间：\n也就是算一下页文件夹项和页表项共占空间 (2^10 * 4 + 2 ^10 *4) = 8KB。\n\n\n\n按《深入理解计算机系统》中的解释，二级模式空间的节约是从两个方面实现的:\nA、假设一级页表中的一个页表条目为空，那么它所指的二级页表就根本不会存在。这表现出一种巨大的潜在节约，对于一个典型程序，4GB虚拟地址空间的大部份都是未分配的。\nB、只有一级页表才需要常驻主存。虚拟内存系统能够在需要时创建、调入或调出二级页表，这就降低了主存的压力，只有最常使用的二级页表才需要缓存在主存中。——只是Linux并没有全然享受这样的福利，它的页表文件夹和与已分配页相关的页表都是常驻内存的。\n\n本文仅介绍一般性转换原理，扩展分页、页的保护机制、PAE模式的分页这些麻烦点的东东就不啰嗦了……需要用到时再参考其他专业书籍。\n\n\n# 5、Linux的页式内存管理\n\n原理上来讲。Linux只需要为每个进程分配好所需数据结构，放到内存中。然后在调度进程的时候，切换寄存器cr3，剩下的就交给硬件来完成了（其实要复杂得多，只是这里仅分析最主要的流程）。\n\n前面说了i386的二级页管理架构。只是有些CPU，还有三级、甚至四级架构。Linux为了在更高层次提供抽象，为所有CPU提供统一接口，提供了一个四层页管理架构，来兼容这些二级、三级、四级管理架构的CPU。这四级分别为：\n页全局文件夹PGD（相应刚才的页文件夹）\n页上级文件夹PUD（新引进的）\n页中间文件夹PMD（新引进的）\n页表PT（相应刚才的页表）。\n\n整个转换依据硬件转换原理，只是多了2次数组的索引罢了。如下图：\nSnap2.jpg \n对于使用二级管理架构32位的硬件，如今又是四级转换了。它们怎么可以协调工作呢？嗯，来看这样的情况下，怎么来划分线性地址吧！\n\n从硬件的角度，32位地址被分成了三部份——也就是说，无论软件怎么做，最终落实到硬件，也只认识这三位老大。\n\n从软件的角度，因为多引入了两部份，也就是说，共同拥有五部份。——要让二层架构的硬件认识五部份也非常easy，在地址划分的时候，将页上级文件夹和页中间文件夹的长度设置为0就够了。\n\n这样，操作系统见到的是五部份，硬件还是按它死板的三部份划分，也不会出错，大家共建了和谐计算机系统。\n\n3部分就能做到的事非要分5部分，虽说是多此一举，可是考虑到64位地址、使用四层转换架构的CPU时，我们就不用再把中间两个设为0了，软硬件依然和谐——抽象就是强大呀！\n\n比如。一个逻辑地址已经被转换成了线性地址，0x08147258，换成二进制，就是：\n0000100000 0101000111 001001011000\n内核对这个地址进行划分\nPGD = 0000100000\nPUD = 0\nPMD = 0\nPT = 0101000111\noffset = 001001011000\n\n如今来理解Linux针对硬件的花招，由于硬件根本看不到所谓PUD、PMD，所以，本质上要求PGD索引，直接就对应了PT地址，而不是再到PUD和PMD中去查数组（尽管它们两个在线性地址中，长度为0，2^0 =1，也就是说，它们都是有一个数组元素的数组），那么，内核怎样合理安排地址呢？\n由于它只有一项，32位，刚好能够存放与PGD中长度一样的地址指针。那么所谓先到PUD，再到PMD中做映射转换，就变成了保持原值不变。一转手就够了。\n这样，就实现了“逻辑上指向一个PUD，再指向一个PDM，但在物理上是直接指向对应的PT”的这个抽象。因为硬件根本不知道有PUD、PMD这两个东西。\n\n然后交给硬件，硬件对这个地址进行划分，看到的是：\n页文件夹 = 0000100000\nPT = 0101000111\noffset = 001001011000\n嗯。先依据0000100000(32)，在页文件夹数组中索引，找到其元素中的地址，取其高20位。找到页表的地址，页表的地址是由内核动态分配的，接着，再加一个offset，就是最终的物理地址了。","tags":["memory"],"categories":["tech"]},{"title":"Linux内存管理及page fault","url":"/blog/tech/Linux_page_fault-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\nLinux对于物理内存的管理方法是:\n由CPU的内存管理单元MMU把物理内存分割成众多个页（page），每个页是4KB，然后把页映射到进程的虚拟内存空间。CPU在执行进程中的指令时， 以虚拟内存地址为基础， 通过map映射， 进而找到物理内存中实际存放指令的地址。\n\n频繁和计算机打交道的人经常可以看到page fault, 那么，\n# 什么是page fault？\n\n严格说， 这里指的是major page fault。名字听起来挺严重， 实际上， 并不是什么“错误”。\n\n大致是这样， 一个程序可能占几Mb， 但并不是所有的指令都要同时运行， 有些是在初始化时运行， 有些是在特定条件下才会去运行。 因此linux并不会把所有的指令都从磁盘加载到page内存。那么当cpu在执行指令时， 如果发现下一条要执行的指令不在实际的物理内存page中时， CPU 就会 raise a page fault， 通知MMU把下面要执行的指令从磁盘加载到物理内存page中。严格说，这里指的是major fault。\n\n既然有major page fault，那么有没有minor page fault呢？\nOf course.\nminor page fault，指的就是CPU要执行的指令实际上已经在物理内存page中了， 只是这个page没有被分配给当前进程，这时CPU就会提交一个minor page fault，让MMU把这个page分配给当前进程使用，因此minor page fault并不需要去访问磁盘。\n\n# 什么是交换分区Swap?\n当物理内存不够时，把一些物理内存page中的内容写入到磁盘，以腾出一些空闲的page出来供进程使用，这个过程叫做swap out。\n\n反过来，当CPU要执行的指令被发现已经swap out到了磁盘中，这时就要从磁盘把这些指令再swap in到物理内存中，让CPU去执行。\n\nswap in和swap out的操作都是比较耗时的, 频繁的swap in和swap out操作很影响系统性能。\n\n-------DONE.-----------","tags":["memory"],"categories":["tech"]},{"title":"Android GPU当前实现及其问题(2014年旧事)","url":"/blog/tech/a_memory_of_2014-undefined.html","content":"\n\n\n# 1. 当前实现\n\n   ![AndroidCurrentImp](/img/2020/AndroidGPU/androidCurrentSolution.jpg)\n   图1 当前的Android GPU实现\n\n   UMD直接通过KMD将cmmand buffer传至DMA buffer。\n\n   DMA buffer和应用之间没有多媒体缓冲队列。\n\n   比如图1中，上方黄绿色的两个APP没有拥堵的话会直接发送到下方DMA buffer。\n\n   \n\n# 2. 问题\n\n## 2.1  硬件需等待GPU流水线同步\n\n如下图，假设有应用APP1发起一次编码请求，它会向UMD发出两个命令ENC和PAK。\n\n这两个命令会直接、同时发送给对应的DMA buffer，如下图所示。\n![problem1](/img/2020/AndroidGPU/androidCurrentSolution_prob01.jpg)\n\n可是在当前实现下，即便PAK自己已经在DMA buffer中做好准备，因为它的前提条件ENC还没结束，PAK会挂起（Engine Stall），直到ENC命令执行完毕。影响GPU性能。\n\n## 2.2 APP没有优先级设定。多个APP同时运行时，很耗资源的背景APP可能会影响硬件和谐\n\n如下图，APP1是时间敏感的应用比如UI，APP2是个占用GPGPU的应用。\n![Problem2](/img/2020/AndroidGPU/androidCurrentSolution_prob02.jpg)\n\n当APP1发出一条命令时，APP2可能已经发出很多条命令了。\n\nKMD可能需要等处理完现有的几条APP2命令后，才能发送APP1的请求，这时对于APP1来说，延时已经产生，可能会影响用户体验，严重时甚至产生拒绝服务（Denial-Of-Service）。\n\n\n\n# 3. 解决方法\n\n如下图，在UMD和KMD直接插入上下文缓冲队列，根据命令优先级和运行时间调度命令送入DMA buffer。\n![insBuf](/img/2020/AndroidGPU/androidCurrentSolution_solution.jpg)\n\n如前面的例1这种情况下，有了这个队列，在暂时block PAK命令的同时，APP2就发送命令给DMA buffer，充分利用VDBOX引擎硬件资源。\n![2Apps](/img/2020/AndroidGPU/androidCurrentSolution_solution2.jpg)\n\n同样，这个调度器按优先级处理队列，在例2这种情况下，仍可保证高优先级的App1获得足够硬件资源。","tags":["GPU"],"categories":["tech"]},{"title":"Inter-Symbol Interference II","url":"/blog/tech/无线通信关键问题-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n多年前觉得需要科普移动通信，但现在全民造手机，热度足够，就不详写了，反正这种枯燥文章没人看。\n\n\n# 符号间干扰（ISI）的由来\n无线信道较之于有线信道更复杂，复杂的原因在于多径与时变。（另一个无线、有线共有的来源是前一期提过的不合格的滤波器）\n\n## 时变\n通信系统的发射端和接收端需要在信号传送期间确保基础时钟的同步，这样才能高效地利用信道，不至于每个最小的信号发送单位都要经过握手、锁定、确认这样的琐碎过程。\n对于有线通信系统，它们很容易建立发射端和接收端的时钟同步机制，比如直接将其中一端的时钟传给另一端作为参考时钟。两个系统的时钟源同步了，也就解决了信号同步的问题。\n\n可是无线系统不一样，接收端没有办法直接获得发射端的时钟。2003年我们这第一批接触3G通信的人找不到任何已有的设计作为参考，只能自己想办法。\n\n有一点是明确的，基站的时钟信息肯定包含在它所调制、发送出来的信号里。所有信息都只能从基站信号里去找去要！我几乎24小时泡在lab里玩弄 Matlab、信号发生器 和 FPGA，几个月后，边构思边尝试出从接收到的无线信号中解析出基站时钟的方法，分几个步骤逐步收敛到需要的解析精度，并专门设计了一个硬件模块（AFC，自动频率控制）来实现算法运算和状态控制，自动跟踪当前基站的时钟，解决了时变的问题。\n\n虽然理论上这个问题肯定能解，而且欧美有现成方案，但那都是别人的，不会给我们看，而且不适用于中国标准，因为无线帧结构不一样。\n当第一个方案真的从自己手中设计、实现出来，而且心里知道将用到中国第一个商用方案上，确实是喜悦非常的。\n\n## 多径 \n（下面几张蓝色图截自网络，文字自己编辑）\n由于建筑物或自然环境（如山林等）的反射或遮挡，无线信号通常不一定能够走直线，直接从发射端发射被接收端接收。这就是无线信号的多径传输。\n![多径](/img/2020/inter-symbol_inteference/multi_path01.jpg \"多径\")\n\n因为这个原因，假如在发送端发送一个窄的脉冲信号，在接收端会接收多个脉冲，本来最短时延是沿最短路径传输所消耗的时间，现在因为多条路径长短不一，所以时延被扩展了，通常将最后一个到达的脉冲，和最先到达的脉冲的时延差，称为最大时延扩展，用Tmax来表示最大时延扩展。\n![Tmax](/img/2020/inter-symbol_inteference/multi_path02.jpg \"Tmax\")\n\n如果这个时延扩展大于两个发送脉冲之间的时间间隔，则会对下一个脉冲的接收产生干扰。\n如果将这两个脉冲看成符号，这称之为符号间干扰（ISI）。\n![ISI](/img/2020/inter-symbol_inteference/multi_path03.jpg \"ISI\")\n\n\n# 符号间干扰（ISI）的解决\n\n## 时钟同步\n解决时钟同步问题，是无线系统解决ISI问题的第一步。（还有个并列第一步，解决滤波器问题）\n\n## 消除多径干扰\n同步问题解决后，要避免接收信号中，一个符号的波形因扩展到其它符号中而造成的干扰，就要将两次发送符号之间的周期扩大，也就是把符号的宽度扩大。扩大多少呢？至少是大于最大时延扩展。\n![扩大时延](/img/2020/inter-symbol_inteference/multi_path04.jpg \"扩大时延\")\n\n而周期扩大，就意味着速率降低了，速率降低，也就意味着带宽降低了。\n![带宽降低](/img/2020/inter-symbol_inteference/multi_path05.jpg \"带宽降低\")\n\n所以系统设计者对于周期扩大是有个容忍极限的，这个极限可以从他们承诺的系统吞吐率参数推算出来。\n\nPath finding模块的任务就是找出同一个symbol（符号）的第一条径信号（通常是主径）和n条能量依次递减的多径接收信号，对它们的偏移量进行调整、对齐后合并，用于后续计算解析。\n\n至此，符号间干扰最直接的几个因素就解决了，其它因素因为事物普遍联系的原因还会有影响但没这么强烈。\n","tags":["silicon","inter-symbol-inteference","filter","jitter","quantify-precision"],"categories":["tech"]},{"title":"Inter-Symbol Interference I","url":"/blog/tech/无线通信系统早期关键问题之一-undefined.html","content":"所有文章全部原创，劳动辛苦，请勿转载。\n\n\n\n成龙大哥的大哥带头用起一种大砖头似的电话，“大哥大”带火了土豪圈。\n这时中国人连手机的生产都不是主力。几年后，电话变薄时，中国工厂变成手机制造主力了，开始关注上游标准。\n\n1998年，3GPP征求3G协议截稿时间的前一刻，原邮电部电信科技研究院出人意料地向3GPP提交了第一份代表中国的移动通信协议，TD-SCDMA。\n*说实话，虽然曾经做得那么深，现在回头查到是1998年提交的这么“老”的一个协议的时候，有些意外，又似乎有那么点印象。现在只记得10年后开始商用。*\n\n不得不说，当时为了能有所突破，争取被接受，这个方案做了些取舍。类似于买东西的性价比，大家现在一听都知道是什么意思。\n比如，当时为了显示出中国方案的独特性和技术突破，做的最大改变就是信号带宽，中国方案只需要1.28MHz，而欧洲和美国方案都是3.84MHz。\n中国其实没有发明新的无线通信原理，和西方同原理不同带宽，技术实现上肯定有硬伤，无可厚非，这时别想着一步登天技术领先，先露下脸比较重要。\n打工人都已经做好了迎接国外黑的准备。\n可是，真的使劲黑的，却是“自己”人。\n有家老大运营商，觉得自己头铁，这种窄带宽的方案自己肯定不会接，就使劲在各种媒体黑。肯定以为自己在提前黑未来的竞争对手。\n当然，几年后，牌照砸到他家，直接指定他来运营TDD，不知道他们当时是什么心情。\n\n回到技术上，真正的质疑声音中，最关键的一个问题是，这套协议的瓶颈，\n##符号间干扰，中国人能克服吗？\n当然提交标准之前，我们老早在实验室里就验证过了，不至于在原则上出问题。在计算机上这个符号间干扰理论上是可以解决的，人家问的是工程上，毕竟就算今天也没人拿CPU来做手机。这个问题有两层含义:\n1）有没有手机芯片来支持解决ISI问题？国外不会帮中国标准设计芯片，只能自己来。\n2）如果这种芯片有了，经济吗？若是需要很高规格，制造成本、功耗很高，用户买不起、用不起，没有实用价值，这个标准就变成面子工程了。\n\n芯片设计与制造直到现在还在被美国卡脖子，十几年前情况只会更差，当时连芯片设计从业者都不多。中国人连2G芯片都没有设计过，上来就直接要参与3G，能玩得起吗？\n\n我当时误打误撞进了上海莘庄的凯明信息，这个全是海归但比较“土”只知道搞技术的公司。后来这家公司第一颗芯片已经流片出来测试成功，准备开发布会的头天晚上，被另一家连FPGA都没跑（注意不是跑“通”哦）的公司抢了新闻，宣布他们已经设计出中国第一颗3G芯片，公开的指标和我们验证中途的数据一样。\n\n在这里，我最初被分配的是匹配滤波器和AFC，path finding这些基础模块。\n\nMatch filter准备采用的是6阶butterworth滤波器，这个很好说，可问题这是模拟电路，不是分立元件，需要采用特定工艺实现芯片设计。\n当时拿到德州仪器的据说是当时性能最好的ABB（模拟基带）芯片，在仪器上测过它的频响曲线发现应该也是6阶butterworth，但是不够平坦，带宽也比中国标准宽（3.84M vs 1.28M）,需要修改。\n仿真结果显示TI设计这款滤波器没有理论支持，参数是拟合butterworth的频响tuning出来的，对于WCDMA，带内纹波可以接受，可是TDD的话，尤其带宽收窄后，纹波（inband ripple）不能接受。\n这其实就涉及到老外的质疑，符号间干扰的问题了，因为这个滤波器是主要的过滤掉符号带外杂波的技术手段，它的性能直接影响带内信号质量和带外干扰。\n如果能有理论支持，就能够得到理想的频响曲线，ISI问题就解决一半了。\n但几位大牛帮忙查阅了那几年的paper，发现就连这种Bi-CMOS本身都属于很新的技术，有文章提到用这种工艺设计放大器，但这时的OTA还远不是理想放大器，基于它来设计滤波器，显然不能生拉硬套现成理论，不然修正起来还不如直接tuning。\n当时年轻，完全没有考虑难度地，就决定自己动手，丰衣足食。\n\n![OTA](/img/2020/inter-symbol_inteference/OTA_circuit1.png \"OTA\")\n图1 其中一路跨导放大器电路\n\n![3rdOrderFilter](/img/2020/inter-symbol_inteference/BiCMOS_Filter_circuit1.png \"3rdOrderFilter\")\n图2 这是从网上拷贝的一个3阶elliptic滤波器电路\n6阶butterworth和这个电路形式相似，复杂度增加一倍。其中的Gm模块就是图1里的跨导放大器电路\n\n发扬愚公移山的精神，把6阶滤波器的所有电路都转换成了一堆数学公式，结果原始公式需要两张A4纸才能写下，方程次数达到几十次。\n兴致勃勃帮忙查资料、分析电路的两位海归博士看看两张A4，互喵一眼，无声地问我：“？”\n这时的理智做法是学习德州仪器，也用仿真软件去tune，简单又没有风险。也不可能有人跳出来说这样做技术不够牛——你牛你上啊。\n\n自己挖的坑，含泪也要坚持，我说：“我打算继续。”看到我对自己数学能力的迷之自信，他们就撤了。\n\n之后一个月，就在两件几乎没什么进展的事情上来回切换：大伤脑筋地想AFC（自动频率控制）方案，想不出来就去解公式。\n公式慢慢解，说不定就能解开呢？\n一个月后，方程次数降到了8阶，形式也简化多了，变成六元8次方程组。然后在一次突发的灵感下，真的解开了。\n两张纸最后变成了两层结构的方程组，顶层是六元一次方程组，用它得到的参数结合芯片制程工艺文件，可以进一步确定滤波器包括跨导放大器内部各个器件的size。离最初猜想的麦克斯韦方程的形式相差十万八千里。但那一瞬间就是有种“我是数学家”的错觉。\n\n之后就和美国TI交流了一番，无条件地告诉了他们这个公式，他们态度180度大转弯，热情得不得了。\n后来还答应直接在他们芯片排期中给我们预留部分产能，帮我们生产同款但滤波器改成中国标准的模拟基带芯片。\n\n滤波器的事情解决了，下一步就是AFC（自动频率控制）和path finding，这也是符号间干扰问题的两个关键影响因素。\n\n（十几年后的现在写这篇回想，有些奇怪当时怎么分配任务的，为什么给我这个新人分配的全是比较基础却和 符号间干扰 这种神级问题相关的模块，而大牛们去做看起来非常复杂但肯定确定以及一定能做出来的turbo解码器、联合检测这样的算法模块？估计是因为我加入得最晚。）","tags":["silicon","3GPP","移动通信","协议"],"categories":["tech"]}]